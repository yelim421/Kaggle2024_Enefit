{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"},{"sourceId":7512619,"sourceType":"datasetVersion","datasetId":4365991},{"sourceId":160761304,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/deeptables-dependecies deeptables==0.2.5","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:12:24.383805Z","iopub.execute_input":"2024-01-30T16:12:24.384177Z","iopub.status.idle":"2024-01-30T16:12:40.098288Z","shell.execute_reply.started":"2024-01-30T16:12:24.384146Z","shell.execute_reply":"2024-01-30T16:12:40.096975Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/deeptables-dependecies\nProcessing /kaggle/input/deeptables-dependecies/deeptables-0.2.5-py3-none-any.whl\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (21.3)\nRequirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (1.11.4)\nRequirement already satisfied: pandas>=0.25.3 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (2.0.3)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (1.24.3)\nRequirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (1.2.2)\nRequirement already satisfied: lightgbm>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (3.3.2)\nRequirement already satisfied: category-encoders>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (2.6.3)\nProcessing /kaggle/input/deeptables-dependecies/hypernets-0.3.1-py3-none-any.whl (from deeptables==0.2.5)\nRequirement already satisfied: h5py>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (3.9.0)\nRequirement already satisfied: eli5 in /opt/conda/lib/python3.10/site-packages (from deeptables==0.2.5) (0.13.0)\nRequirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from category-encoders>=2.1.0->deeptables==0.2.5) (0.14.0)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from category-encoders>=2.1.0->deeptables==0.2.5) (0.5.3)\nRequirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (2023.12.2)\nRequirement already satisfied: ipython in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (8.14.0)\nRequirement already satisfied: traitlets in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (5.9.0)\nProcessing /kaggle/input/deeptables-dependecies/XlsxWriter-3.1.9-py3-none-any.whl (from hypernets>=0.2.5.1->deeptables==0.2.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (6.0.1)\nProcessing /kaggle/input/deeptables-dependecies/paramiko-3.4.0-py3-none-any.whl (from hypernets>=0.2.5.1->deeptables==0.2.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (2.31.0)\nRequirement already satisfied: tornado in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (6.3.3)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (3.8.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (4.66.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from hypernets>=0.2.5.1->deeptables==0.2.5) (1.3.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm>=2.2.0->deeptables==0.2.5) (0.41.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->deeptables==0.2.5) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->deeptables==0.2.5) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->deeptables==0.2.5) (2023.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->deeptables==0.2.5) (3.2.0)\nRequirement already satisfied: attrs>17.1.0 in /opt/conda/lib/python3.10/site-packages (from eli5->deeptables==0.2.5) (23.1.0)\nRequirement already satisfied: jinja2>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from eli5->deeptables==0.2.5) (3.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from eli5->deeptables==0.2.5) (1.16.0)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from eli5->deeptables==0.2.5) (0.20.1)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from eli5->deeptables==0.2.5) (0.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->deeptables==0.2.5) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=3.0.0->eli5->deeptables==0.2.5) (2.1.3)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.19.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.1.6)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (3.0.39)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (2.16.1)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (4.8.0)\nProcessing /kaggle/input/deeptables-dependecies/bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (from paramiko->hypernets>=0.2.5.1->deeptables==0.2.5)\nRequirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.10/site-packages (from paramiko->hypernets>=0.2.5.1->deeptables==0.2.5) (40.0.2)\nProcessing /kaggle/input/deeptables-dependecies/PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (from paramiko->hypernets>=0.2.5.1->deeptables==0.2.5)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->hypernets>=0.2.5.1->deeptables==0.2.5) (0.2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->hypernets>=0.2.5.1->deeptables==0.2.5) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->hypernets>=0.2.5.1->deeptables==0.2.5) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->hypernets>=0.2.5.1->deeptables==0.2.5) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->hypernets>=0.2.5.1->deeptables==0.2.5) (2023.11.17)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.3->paramiko->hypernets>=0.2.5.1->deeptables==0.2.5) (1.15.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.7.0)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->hypernets>=0.2.5.1->deeptables==0.2.5) (0.2.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko->hypernets>=0.2.5.1->deeptables==0.2.5) (2.21)\nInstalling collected packages: XlsxWriter, bcrypt, pynacl, paramiko, hypernets, deeptables\nSuccessfully installed XlsxWriter-3.1.9 bcrypt-4.1.2 deeptables-0.2.5 hypernets-0.3.1 paramiko-3.4.0 pynacl-1.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport math\nimport numpy as np \nimport pandas as pd \nimport polars as pl \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport holidays\nimport lightgbm as lgb\nimport tensorflow as tf, deeptables as dt\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow_addons.optimizers import AdamW\nfrom tensorflow.python.keras import backend as K\nfrom deeptables.models import DeepTable, ModelConfig\nfrom deeptables.models import deepnets\nimport joblib\nfrom datetime import timedelta\n\nprint('Tensorflow version:', tf.__version__)\nprint('DeepTables version:', dt.__version__)\n\nfrom fastai.tabular.all import *\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:12:40.100836Z","iopub.execute_input":"2024-01-30T16:12:40.101293Z","iopub.status.idle":"2024-01-30T16:13:02.932912Z","shell.execute_reply.started":"2024-01-30T16:12:40.101247Z","shell.execute_reply":"2024-01-30T16:13:02.931771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tensorflow version: 2.13.0\nDeepTables version: 0.2.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport ctypes\n\nseed = 42\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=seed)\n\ndef clean_memory():\n    gc.collect()\n    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n    \nclean_memory()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:02.934378Z","iopub.execute_input":"2024-01-30T16:13:02.935326Z","iopub.status.idle":"2024-01-30T16:13:03.261923Z","shell.execute_reply.started":"2024-01-30T16:13:02.935280Z","shell.execute_reply":"2024-01-30T16:13:03.260464Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DataStorage:\n    \"\"\"\n    This class was copied out from:\n    https://www.kaggle.com/code/vitalykudelya/enefit-object-oriented-gbdt\n    \"\"\"\n    \n    root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n\n    data_cols = [\n        \"target\",\n        \"county\",\n        \"is_business\",\n        \"product_type\",\n        \"is_consumption\",\n        \"datetime\",\n        \"row_id\",\n        \"prediction_unit_id\",\n    ]\n    client_cols = [\n        \"product_type\",\n        \"county\",\n        \"eic_count\",\n        \"installed_capacity\",\n        \"is_business\",\n        \"date\",\n    ]\n    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n    forecast_weather_cols = [\n        \"latitude\",\n        \"longitude\",\n        \"hours_ahead\",\n        \"temperature\",\n        \"dewpoint\",\n        \"cloudcover_high\",\n        \"cloudcover_low\",\n        \"cloudcover_mid\",\n        \"cloudcover_total\",\n        \"10_metre_u_wind_component\",\n        \"10_metre_v_wind_component\",\n        \"forecast_datetime\",\n        \"direct_solar_radiation\",\n        \"surface_solar_radiation_downwards\",\n        \"snowfall\",\n        \"total_precipitation\",\n    ]\n    historical_weather_cols = [\n        \"datetime\",\n        \"temperature\",\n        \"dewpoint\",\n        \"rain\",\n        \"snowfall\",\n        \"surface_pressure\",\n        \"cloudcover_total\",\n        \"cloudcover_low\",\n        \"cloudcover_mid\",\n        \"cloudcover_high\",\n        \"windspeed_10m\",\n        \"winddirection_10m\",\n        \"shortwave_radiation\",\n        \"direct_solar_radiation\",\n        \"diffuse_radiation\",\n        \"latitude\",\n        \"longitude\",\n    ]\n    location_cols = [\"longitude\", \"latitude\", \"county\"]\n    target_cols = [\n        \"target\",\n        \"county\",\n        \"is_business\",\n        \"product_type\",\n        \"is_consumption\",\n        \"datetime\",\n    ]\n\n    def __init__(self, root=root):\n        self.df_data = pl.read_csv(\n            os.path.join(root, \"train.csv\"),\n            columns=self.data_cols,\n            try_parse_dates=True,\n        )\n        self.df_client = pl.read_csv(\n            os.path.join(root, \"client.csv\"),\n            columns=self.client_cols,\n            try_parse_dates=True,\n        )\n        self.df_gas_prices = pl.read_csv(\n            os.path.join(root, \"gas_prices.csv\"),\n            columns=self.gas_prices_cols,\n            try_parse_dates=True,\n        )\n        self.df_electricity_prices = pl.read_csv(\n            os.path.join(root, \"electricity_prices.csv\"),\n            columns=self.electricity_prices_cols,\n            try_parse_dates=True,\n        )\n        self.df_electricity_prices = self.df_electricity_prices.with_columns(\n            self.df_electricity_prices['euros_per_mwh'].abs().alias('euros_per_mwh')\n        )\n        self.df_forecast_weather = pl.read_csv(\n            os.path.join(root, \"forecast_weather.csv\"),\n            columns=self.forecast_weather_cols,\n            try_parse_dates=True,\n        )\n        self.df_historical_weather = pl.read_csv(\n            os.path.join(root, \"historical_weather.csv\"),\n            columns=self.historical_weather_cols,\n            try_parse_dates=True,\n        )\n        self.df_weather_station_to_county_mapping = pl.read_csv(\n            os.path.join(root, \"weather_station_to_county_mapping.csv\"),\n            columns=self.location_cols,\n            try_parse_dates=True,\n        )\n#         self.df_data = self.df_data.filter(\n#             pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n#         )\n        self.df_target = self.df_data.select(self.target_cols)\n    \n        print('data_storage initialized.')\n        print('df_client', self.df_client.shape)\n        print('df_gas_prices', self.df_gas_prices.shape)\n        print('df_electricity_prices', self.df_electricity_prices.shape)\n        print('df_forecast_weather', self.df_forecast_weather.shape)\n        print('df_historical_weather', self.df_historical_weather.shape)\n        print('df_target', self.df_target.shape)\n    \n        self.schema_data = self.df_data.schema\n        self.schema_client = self.df_client.schema\n        self.schema_gas_prices = self.df_gas_prices.schema\n        self.schema_electricity_prices = self.df_electricity_prices.schema\n        self.schema_forecast_weather = self.df_forecast_weather.schema\n        self.schema_historical_weather = self.df_historical_weather.schema\n        self.schema_target = self.df_target.schema\n\n        self.df_weather_station_to_county_mapping = (\n            self.df_weather_station_to_county_mapping.with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n        )\n        \n    def run(self):\n        self.df_data = self.fill_target(self.df_data)\n        self.df_forecast_weather = self.fill_radiation(self.df_forecast_weather)\n        self.df_forecast_weather = self.fill_summertime(self.df_forecast_weather)\n        self.df_forecast_weather = self.separateTP(self.df_forecast_weather)\n        self.df_forecast_weather = self.expForecastHr(self.df_forecast_weather)\n        self.df_forecast_weather = self.snow2water(self.df_forecast_weather)\n        return self\n    \n    def run_test(self):\n#         self.df_forecast_weather = self.separateTP(self.df_forecast_weather)\n#         self.df_forecast_weather = self.expForecastHr(self.df_forecast_weather)\n#         self.df_forecast_weather = self.snow2water(self.df_forecast_weather)\n        pass\n        return self\n    \n        \n    def fill_target(self, df):\n        def _interpolate_group(group):\n            group['target'] = group['target'].interpolate(method='linear')\n            return group\n        return pl.DataFrame(df.to_pandas().groupby(['prediction_unit_id', 'is_consumption']).apply(_interpolate_group))\n\n    def fill_radiation(self, df):\n        rad = df.to_pandas()['surface_solar_radiation_downwards'].values\n        idx = df['surface_solar_radiation_downwards'].is_null().to_numpy().nonzero()[0]\n        for i, ind in enumerate(idx):\n            tmp = df[idx][i]\n            df_b1 = df.filter(\n                pl.col('latitude') == tmp['latitude'], \n                pl.col('longitude') == tmp['longitude'],\n                abs(pl.col('forecast_datetime') - tmp['forecast_datetime']) < timedelta(days=2),\n                pl.col('forecast_datetime').dt.hour() == tmp['forecast_datetime'].dt.hour(),\n                pl.col('hours_ahead') == tmp['hours_ahead'])\n\n            # 결측값 검사 및 안전한 나눗셈\n            if df_b1['direct_solar_radiation'][0] is not None and df_b1['surface_solar_radiation_downwards'][0] not in [None, 0] \\\n               and df_b1['direct_solar_radiation'][2] is not None and df_b1['surface_solar_radiation_downwards'][2] not in [None, 0]:\n                fillValue = df_b1['direct_solar_radiation'][1] / ((np.divide(df_b1['direct_solar_radiation'][0], df_b1['surface_solar_radiation_downwards'][0]) +\n                    np.divide(df_b1['direct_solar_radiation'][2], df_b1['surface_solar_radiation_downwards'][2]))/2)\n                rad[ind] = fillValue\n            else:\n                rad[ind] = 0  # 결측값 대체를 위한 기본값 설정\n\n        df.replace('surface_solar_radiation_downwards', pl.Series(rad))\n        return df\n\n\n    def fill_summertime(self, df):\n        missingDate = list(set(pd.date_range('2021-09-01', '2023-06-02', freq='h')[3:-22]) - set(df.to_pandas()['forecast_datetime'].unique()))\n        hrs_ahead = 2\n        add_df = pd.DataFrame()\n        for date in missingDate:\n            tmp = df.filter(abs(pl.col('forecast_datetime') - date) < timedelta(hours=2),\n                            pl.col('hours_ahead') <= 2).sort('latitude', 'longitude').to_pandas()\n            values_1 = None  # 초기화\n            for _, row in tmp.iterrows():\n                if row['hours_ahead'] == 1:\n                    values_1 = row\n                elif row['hours_ahead'] == 2 and values_1 is not None:\n                    values_2 = row\n                    average_values = pd.Series([(v1+v2)/2 if c != 'forecast_datetime' else date for (v1,v2,c) in zip(values_1,values_2,values_2.keys())],\n                                            index=values_2.keys())\n                    average_values['hours_ahead'] = hrs_ahead\n                    add_df = pd.concat([add_df, average_values.to_frame().T]).reset_index(drop=True)\n        return pl.DataFrame(pd.concat([df.to_pandas(), add_df]).reset_index(drop=True))\n\n\n    def snow2water(self, df): # for historical: [cm]/7->[mm]\n        return df.with_columns(\n            (df['snowfall']/7).alias('snowfall_mm'))\n\n    def separateTP(self, df): \n    # Adjust the indentation as needed to match the rest of your class\n        df = df.with_columns([\n            (df['total_precipitation'] - df['snowfall'] / 100).alias('rain')\n        ])\n        return df\n\n    def expForecastHr(self, df):\n    # Ensure the indentation here matches the rest of your class\n        def _exp(x):\n            return np.exp(x) / np.exp(48)\n\n        df = df.with_columns([\n            df['hours_ahead'].apply(_exp).alias('exp_hours_ahead')\n        ])\n        return df\n    \n    def update_with_new_data(\n        self,\n        df_new_client,\n        df_new_gas_prices,\n        df_new_electricity_prices,\n        df_new_forecast_weather,\n        df_new_historical_weather,\n        df_new_target,\n    ):\n        print('start to update with new data..')\n        print('df_new_client', df_new_client.shape)\n        print('df_new_gas_prices', df_new_gas_prices.shape)\n        print('df_new_electricity_prices', df_new_electricity_prices.shape)\n        print('df_new_forecast_weather', df_new_forecast_weather.shape)\n        print('df_new_historical_weather', df_new_historical_weather.shape)\n        print('df_new_target', df_new_target.shape)\n        \n        df_new_data = df_new_target.copy()\n        \n        df_new_data = pl.from_pandas(\n            df_new_data[self.data_cols], schema_overrides=self.schema_data\n        )\n        df_new_client = pl.from_pandas(\n            df_new_client[self.client_cols], schema_overrides=self.schema_client\n        )\n        df_new_gas_prices = pl.from_pandas(\n            df_new_gas_prices[self.gas_prices_cols],\n            schema_overrides=self.schema_gas_prices,\n        )\n        df_new_electricity_prices = pl.from_pandas(\n            df_new_electricity_prices[self.electricity_prices_cols],\n            schema_overrides=self.schema_electricity_prices,\n        )\n        df_new_forecast_weather = pl.from_pandas(\n            df_new_forecast_weather[self.forecast_weather_cols],\n            schema_overrides=self.schema_forecast_weather,\n        )\n        \n        df_new_forecast_weather = self.separateTP(df_new_forecast_weather)\n        df_new_forecast_weather = self.expForecastHr(df_new_forecast_weather)\n        df_new_forecast_weather = self.snow2water(df_new_forecast_weather)\n\n        df_new_historical_weather = pl.from_pandas(\n            df_new_historical_weather[self.historical_weather_cols],\n            schema_overrides=self.schema_historical_weather,\n        )\n        df_new_target = pl.from_pandas(\n            df_new_target[self.target_cols], schema_overrides=self.schema_target\n        )\n\n#         self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n#             [\"date\", \"county\", \"is_business\", \"product_type\"]\n#         )\n#         self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n#             [\"forecast_date\"]\n#         )\n#         self.df_electricity_prices = pl.concat(\n#             [self.df_electricity_prices, df_new_electricity_prices]\n#         ).unique([\"forecast_date\"])\n#         self.df_forecast_weather = pl.concat(\n#             [self.df_forecast_weather, df_new_forecast_weather]\n#         ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n#         self.df_historical_weather = pl.concat(\n#             [self.df_historical_weather, df_new_historical_weather]\n#         ).unique([\"datetime\", \"latitude\", \"longitude\"])\n#         self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n#             [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n#         )\n\n        self.df_client = df_new_client.unique(\n            [\"date\", \"county\", \"is_business\", \"product_type\"]\n        )\n        self.df_gas_prices = df_new_gas_prices.unique(\n            [\"forecast_date\"]\n        )\n        self.df_electricity_prices = df_new_electricity_prices.unique([\"forecast_date\"])\n        self.df_forecast_weather = df_new_forecast_weather.unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n        self.df_historical_weather = df_new_historical_weather.unique([\"datetime\", \"latitude\", \"longitude\"])\n        self.df_target = df_new_target.unique(\n            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n        )\n\n        print('\\n')\n        print('data_storage updated!')\n        print('df_client', self.df_client.shape)\n        print('df_gas_prices', self.df_gas_prices.shape)\n        print('df_electricity_prices', self.df_electricity_prices.shape)\n        print('df_forecast_weather', self.df_forecast_weather.shape)\n        print('df_historical_weather', self.df_historical_weather.shape)\n        print('df_target', self.df_target.shape)\n        \n\n    def preprocess_test(self, df_test):\n        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n        df_test = pl.from_pandas(\n            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n        )\n        return df_test","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.265771Z","iopub.execute_input":"2024-01-30T16:13:03.266702Z","iopub.status.idle":"2024-01-30T16:13:03.311854Z","shell.execute_reply.started":"2024-01-30T16:13:03.266650Z","shell.execute_reply":"2024-01-30T16:13:03.310835Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class FeaturesGenerator:\n    \"\"\"\n    This class was copied out from:\n    https://www.kaggle.com/code/vitalykudelya/enefit-object-oriented-gbdt\n    \"\"\"\n    def __init__(self, data_storage):\n        self.data_storage = data_storage\n\n    def _add_general_features(self, df_features):\n        df_features = (\n            df_features.with_columns(\n                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n                pl.col(\"datetime\").dt.day().alias(\"day\"),\n                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n                pl.col(\"datetime\").dt.month().alias(\"month\"),\n                pl.col(\"datetime\").dt.year().alias(\"year\"),\n            )\n            .with_columns(\n                pl.concat_str(\n                    \"county\",\n                    \"is_business\",\n                    \"product_type\",\n                    \"is_consumption\",\n                    separator=\"_\",\n                ).alias(\"segment\"),\n            )\n            .with_columns(\n                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n            )\n        )\n        return df_features\n\n    def _add_client_features(self, df_features):\n        df_client = self.data_storage.df_client\n\n        df_features = df_features.join(\n            df_client.with_columns(\n                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n            ),\n            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n            how=\"left\",\n        )\n        return df_features\n\n    def _add_forecast_weather_features(self, df_features):\n        df_forecast_weather = self.data_storage.df_forecast_weather\n        df_weather_station_to_county_mapping = (\n            self.data_storage.df_weather_station_to_county_mapping\n        )\n\n        df_forecast_weather = (\n            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n            .drop(\"hours_ahead\")\n            .with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n            .join(\n                df_weather_station_to_county_mapping,\n                how=\"left\",\n                on=[\"longitude\", \"latitude\"],\n            )\n            .drop(\"longitude\", \"latitude\")\n        )\n\n        df_forecast_weather_date = (\n            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n        )\n\n        df_forecast_weather_local = (\n            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n            .group_by(\"county\", \"datetime\")\n            .mean()\n        )\n        \n        for hours_lag in [0]: # 7 * 24]:\n            df_features = df_features.join(\n                df_forecast_weather_date.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=\"datetime\",\n                how=\"left\",\n                suffix=f\"_forecast\", #_{hours_lag}h\",\n            )\n            df_features = df_features.join(\n                df_forecast_weather_local.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=[\"county\", \"datetime\"],\n                how=\"left\",\n                suffix=f\"_forecast_local\", #_{hours_lag}h\",\n            )\n\n        return df_features\n\n    def _add_historical_weather_features(self, df_features):\n        df_historical_weather = self.data_storage.df_historical_weather\n        df_weather_station_to_county_mapping = (\n            self.data_storage.df_weather_station_to_county_mapping\n        )\n\n        df_historical_weather = (\n            df_historical_weather.with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n            .join(\n                df_weather_station_to_county_mapping,\n                how=\"left\",\n                on=[\"longitude\", \"latitude\"],\n            )\n            .drop(\"longitude\", \"latitude\")\n        )\n\n        df_historical_weather_date = (\n            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n        )\n\n        df_historical_weather_local = (\n            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n            .group_by(\"county\", \"datetime\")\n            .mean()\n        )\n\n\n        for hours_lag in [0]: #[2 * 24, 7 * 24]:\n            df_features = df_features.join(\n                df_historical_weather_date.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=\"datetime\",\n                how=\"left\",\n                suffix=f\"_historical\", #_{hours_lag}h\",\n            )\n            df_features = df_features.join(\n                df_historical_weather_local.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=[\"county\", \"datetime\"],\n                how=\"left\",\n                suffix=f\"_historical_local\", #_{hours_lag}h\",\n            )\n\n        return df_features\n\n#     def _add_target_features(self, df_features):\n#         df_target = self.data_storage.df_target\n\n#         df_target_all_type_sum = (\n#             df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n#             .sum()\n#             .drop(\"product_type\")\n#         )\n\n#         df_target_all_county_type_sum = (\n#             df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n#             .sum()\n#             .drop(\"product_type\", \"county\")\n#         )\n\n#         for hours_lag in [\n#             2 * 24,\n#             3 * 24,\n#             4 * 24,\n#             5 * 24,\n#             6 * 24,\n#             7 * 24,\n#             8 * 24,\n#             9 * 24,\n#             10 * 24,\n#             11 * 24,\n#             12 * 24,\n#             13 * 24,\n#             14 * 24,\n#             6,      ###\n#             12,     ###\n#             84,     ###\n#         ]:\n#             df_features = df_features.join(\n#                 df_target.with_columns(\n#                     pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n#                 ).rename({\"target\": f\"target_{hours_lag}h\"}),\n#                 on=[\n#                     \"county\",\n#                     \"is_business\",\n#                     \"product_type\",\n#                     \"is_consumption\",\n#                     \"datetime\",\n#                 ],\n#                 how=\"left\",\n#             )\n\n#         for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n#             df_features = df_features.join(\n#                 df_target_all_type_sum.with_columns(\n#                     pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n#                 ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n#                 on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n#                 how=\"left\",\n#             )\n\n#             df_features = df_features.join(\n#                 df_target_all_county_type_sum.with_columns(\n#                     pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n#                 ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n#                 on=[\"is_business\", \"is_consumption\", \"datetime\"],\n#                 how=\"left\",\n#                 suffix=f\"_all_county_type_sum_{hours_lag}h\",\n#             )\n\n#         cols_for_stats = [\n#             f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n#         ]\n#         df_features = df_features.with_columns(\n#             df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n#             df_features.select(cols_for_stats)\n#             .transpose()\n#             .std()\n#             .transpose()\n#             .to_series()\n#             .alias(f\"target_std\"),\n#         )\n\n#         for target_prefix, lag_nominator, lag_denomonator in [\n#             (\"target\", 24 * 7, 24 * 14),\n#             (\"target\", 24 * 2, 24 * 9),\n#             (\"target\", 24 * 3, 24 * 10),\n#             (\"target\", 24 * 2, 24 * 3),\n#             (\"target_all_type_sum\", 24 * 2, 24 * 3),\n#             (\"target_all_type_sum\", 24 * 7, 24 * 14),\n#             (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n#             (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n#         ]:\n#             df_features = df_features.with_columns(\n#                 (\n#                     pl.col(f\"{target_prefix}_{lag_nominator}h\")\n#                     / (pl.col(f\"{target_prefix}_{lag_denomonator}h\") + 1e-3)\n#                 ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denomonator}\")\n#             )\n\n#         return df_features\n\n    def _reduce_memory_usage(self, df_features):\n        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n        return df_features\n\n    def _drop_columns(self, df_features):\n        df_features = df_features.drop(\n           \"datetime\", \"hour\", \"dayofyear\"\n        )\n        return df_features\n\n    def _to_pandas(self, df_features, y):\n        cat_cols = [\n            \"county\",\n            \"is_business\",\n            \"product_type\",\n            \"is_consumption\",\n            \"segment\",\n        ]\n\n        if y is not None:\n            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n        else:\n            df_features = df_features.to_pandas()\n\n        df_features = df_features.set_index(\"row_id\")\n        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n\n        return df_features\n\n    def generate_features(self, df_prediction_items):\n        if \"target\" in df_prediction_items.columns:\n            df_prediction_items, y = (\n                df_prediction_items.drop(\"target\"),\n                df_prediction_items.select(\"target\"),\n            )\n        else:\n            y = None\n\n        df_features = df_prediction_items.with_columns(\n            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n        ).with_columns(pl.col(\"datetime\").dt.cast_time_unit(\"us\").alias(\"datetime\"))\n\n        for add_features in [\n            self._add_general_features,\n            self._add_client_features,\n            self._add_forecast_weather_features,\n            self._add_historical_weather_features,\n            #self._add_target_features,\n            self._reduce_memory_usage,\n            self._drop_columns,\n        ]:\n            df_features = add_features(df_features)\n\n        df_features = self._to_pandas(df_features, y)\n\n        return df_features","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.313702Z","iopub.execute_input":"2024-01-30T16:13:03.314657Z","iopub.status.idle":"2024-01-30T16:13:03.348061Z","shell.execute_reply.started":"2024-01-30T16:13:03.314608Z","shell.execute_reply":"2024-01-30T16:13:03.346675Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# def convert_2_dataloader(df, _seed):\n\n#     # define categorical and continous numerical feature column names (on small number of features)\n#     # from train.csv\n#     cat_names = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"segment\"]\n#     # from datetime column\n#     cat_names += [\"weekday\", \"month\", 'sin(dayofyear)', 'cos(dayofyear)', 'sin(hour)', 'cos(hour)']\n#     # from https://www.kaggle.com/code/albansteff/enefit-estonian-holidays-lb-65-79 notebook\n#     cat_names += ['country_holiday']\n    \n#     # from client.csv\n#     cont_names = [\"installed_capacity\", \"eic_count\"]\n    \n#     # from forecast_weather.csv (next 0 hours)\n#     cont_names += [_ for _ in df.columns if \"_forecast_0h\" in _]\n#     cont_names += [_ for _ in df.columns if \"_forecast_local_0h\" in _]\n#     # from forecast_weather.csv (next 24 hours)\n#     cont_names += [_ for _ in df.columns if \"_forecast_24h\" in _]\n#     cont_names += [_ for _ in df.columns if \"_forecast_local_24h\" in _]\n    \n#     # from historical_weather.csv (last 24/48 hours)\n#     cont_names += [_ for _ in df.columns if \"_historical_24h\" in _]\n#     cont_names += [_ for _ in df.columns if \"_historical_48h\" in _]\n#     cont_names += [_ for _ in df.columns if \"_historical_local_48h\" in _]\n    \n#     # add all historical target values (last n hours)\n#     cont_names += df.filter(regex=(\"target_.[0-9]*h\")).columns.tolist()\n#     cont_names += ['target_mean', 'target_std']\n    \n#     # added aggregated target values\n#     cont_names += [_ for _ in df.columns if \"target_all_\" in _]\n    \n#     # add ratios between last kown target values\n#     cont_names += df.filter(regex=(\"target_ratio_.[0-9]\")).columns.tolist()\n    \n#     procs = [Categorify, FillMissing, Normalize]\n    \n#     # log transform target variable\n#     df.loc[:, 'target'] = np.log1p(df['target'])\n        \n#     # convert pandas DataFrame to fastai DataLoader object\n#     # code snippet taken from\n#     # https://docs.fast.ai/tabular.learner.html\n#     splits = RandomSplitter(valid_pct=0.2, seed = _seed)(df)\n    \n#     # tabular object (only categorical features)\n#     to = TabularPandas(df[cat_names + cont_names + [\"target\"]],\n#                        procs = procs,\n#                        cat_names = cat_names,\n#                        cont_names = cont_names,\n#                        y_names = [\"target\"],\n#                        splits=splits)\n#     # create dataloader\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     dls = to.dataloaders(BATCH_SIZE, device = device)\n     \n#     # return all dataloaders as tuple\n#     return dls\n\ndef add_custom_features(df):\n    \"\"\"\n    Function inspired by notebook:\n    https://www.kaggle.com/code/albansteff/enefit-estonian-holidays-lb-65-79\n    \"\"\"\n    \n    # code bellow same as in NB v17 add_holidays_as_binary_features function\n    estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\n    estonian_holidays = [pd.to_datetime(_) for _ in estonian_holidays.keys()]\n    \n    df['country_holiday'] = df['date'].isin(estonian_holidays) * 1\n    del df['date']\n    \n    # log transform histrocial target values\n    _cols = df.filter(regex=(\"target_.[0-9]*h\")).columns.tolist()\n    for _col in _cols:\n        df.loc[:, _col] = np.log1p(df[_col])\n    \n    # log transform aggregated target values\n    _cols = [_ for _ in df.columns if \"target_all_\" in _]\n    for _col in _cols:\n        df.loc[:, _col] = np.log1p(df[_col])  \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.350075Z","iopub.execute_input":"2024-01-30T16:13:03.350486Z","iopub.status.idle":"2024-01-30T16:13:03.367272Z","shell.execute_reply.started":"2024-01-30T16:13:03.350447Z","shell.execute_reply":"2024-01-30T16:13:03.366362Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DataTransformer:\n    def __init__(self, df, isTrain=True):\n        self.df = df\n        self.isTrain = isTrain\n\n    def transform(self):\n        self.add_season()\n        self.add_daypart_with_sin_hour()\n        self.add_feels_like_temperature()\n#         self.add_energy_usage_trend()\n#         self.add_temp_change()\n#         self.add_prec_change()\n#         self.add_autocorr_features()\n#         self.add_energy_price_volatility_and_trend()\n#         self.perform_clustering()\n        self.analyze_transit_and_charging_access(self.isTrain)\n        return self.df\n\n    def add_season(self):\n        def get_season(month):\n            if month in [3, 4, 5]:\n                return 1 #spring\n            elif month in [6, 7, 8]:\n                return 2 #summer\n            elif month in [9, 10, 11]:\n                return 3 #fall\n            else:\n                return 4 #winter\n        \n        self.df['season'] = self.df['month'].apply(get_season)\n\n    def add_daypart_with_sin_hour(self):\n        def get_daypart(sin_hour):\n            if sin_hour > 0:\n                return 1  # sin(hour) 양수: 오전~오후\n            else:\n                return 2  # sin(hour) 음수: 저녁~밤\n\n        self.df['daypart'] = self.df['sin(hour)'].apply(get_daypart)\n\n    def add_feels_like_temperature(self):\n        def calculate_feels_like(T, u, v):\n            wind_speed = (u**2 + v**2)**0.5\n            if wind_speed < 4.8:\n                return T\n            else:\n                return 13.12 + 0.6215 * T - 11.37 * (wind_speed ** 0.16) + 0.3965 * T * (wind_speed ** 0.16)\n\n        self.df['feels_like_temp'] = self.df.apply(lambda row: calculate_feels_like(row['temperature'], row['10_metre_u_wind_component'], row['10_metre_v_wind_component']), axis=1)\n\n\n#     def add_temp_change(self, interval = 24):\n#         self.df['temp_change'] = self.df['temperature'].diff(periods = interval)\n        \n#     def add_prec_change(self):\n#         self.df['precipitation_change'] = self.df['total_precipitation'].diff()\n\n#     def add_autocorr_features(self, lags = 10):\n#         acf_values = acf(self.df['target'], nlags = lags)\n#         pacf_values = pacf(self.df['target'], nlags = lags)\n#         for i in range(lags+1):\n#             self.df[f'acf_lag_{i}'] = acf_values[i]\n#             self.df[f'pacf_lag{i}'] = pacf_values[i]\n\n    def analyze_transit_and_charging_access(self, isTrain):\n        if isTrain == True:\n            results = []\n            for consumption_status in [0, 1]:\n                subset = self.df[self.df['is_consumption'] == consumption_status]\n\n                # 대중교통 이용률 분석\n                business_hours_energy = subset[subset['is_business'] == 1]['target'].mean()\n                non_business_hours_energy = subset[subset['is_business'] == 0]['target'].mean()\n                transit_usage_estimate = business_hours_energy - non_business_hours_energy\n\n                # 전기차 충전소 접근성 분석\n                high_capacity_energy = subset[subset['installed_capacity'] > subset['installed_capacity'].median()]['target'].mean()\n                low_capacity_energy = subset[subset['installed_capacity'] <= subset['installed_capacity'].median()]['target'].mean()\n                charging_access_estimate = high_capacity_energy - low_capacity_energy\n\n                results.append((consumption_status, transit_usage_estimate, charging_access_estimate))\n\n            # 결과를 하나의 컬럼으로 합침\n            for consumption_status, transit_estimate, charging_estimate in results:\n                self.df[f'transit_usage_estimate_{consumption_status}'] = transit_estimate\n                self.df[f'charging_access_estimate_{consumption_status}'] = charging_estimate\n                \n        else: #test stage\n            self.df['transit_usage_estimate_0'] = train_dataset['transit_usage_estimate_0'][0]\n            self.df['charging_access_estimate_0'] = train_dataset['charging_access_estimate_0'][0]\n            self.df['transit_usage_estimate_1'] = train_dataset['transit_usage_estimate_1'][0]\n            self.df['charging_access_estimate_1'] = train_dataset['charging_access_estimate_1'][0]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.371433Z","iopub.execute_input":"2024-01-30T16:13:03.371897Z","iopub.status.idle":"2024-01-30T16:13:03.395894Z","shell.execute_reply.started":"2024-01-30T16:13:03.371861Z","shell.execute_reply":"2024-01-30T16:13:03.394819Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#train_dataset data 변환 (weekday -> weekend, wind dir, speed -> U10, V10)\nclass TrainDataTransform:\n    def __init__(self, df):\n        self.df = df\n\n    def transform(self):\n        self.is_weekend()\n        self.wind_data_to_UV()\n        return self.df\n\n    #weekend 판별 함수\n    def is_weekend(self):\n        self.df['is_weekend'] = np.where(self.df['weekday'] > 4, 1, 0)\n        \n    def wind_data_to_UV(self):\n        self.df['U10'] = self.df['windspeed_10m'] * np.cos(np.radians(270 - self.df['winddirection_10m']))\n        self.df['V10'] = self.df['windspeed_10m'] * np.sin(np.radians(270 - self.df['winddirection_10m']))\n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.397590Z","iopub.execute_input":"2024-01-30T16:13:03.398392Z","iopub.status.idle":"2024-01-30T16:13:03.415048Z","shell.execute_reply.started":"2024-01-30T16:13:03.398347Z","shell.execute_reply":"2024-01-30T16:13:03.414053Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data_storage = DataStorage()\ndata_storage = data_storage.run()\n\nfeatures_generator = FeaturesGenerator(data_storage=data_storage)\n\ntrain_dataset = features_generator.generate_features(data_storage.df_data)\ntrain_dataset = train_dataset[train_dataset['target'].notnull()]\ntrain_dataset = add_custom_features(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:03.418033Z","iopub.execute_input":"2024-01-30T16:13:03.418502Z","iopub.status.idle":"2024-01-30T16:13:47.477460Z","shell.execute_reply.started":"2024-01-30T16:13:03.418422Z","shell.execute_reply":"2024-01-30T16:13:47.476423Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"data_storage initialized.\ndf_client (41919, 6)\ndf_gas_prices (637, 3)\ndf_electricity_prices (15286, 2)\ndf_forecast_weather (3424512, 16)\ndf_historical_weather (1710802, 17)\ndf_target (2018352, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"#이거 먼저 와야함\ntrain_dataset['eic_count'] = train_dataset['eic_count'].fillna(method = 'bfill')\ntrain_dataset['installed_capacity'] = train_dataset['installed_capacity'].fillna(method = 'bfill')\n\ntrain_dataset = DataTransformer(train_dataset)\ntrain_dataset = train_dataset.transform()\n\ntrain_dataset = TrainDataTransform(train_dataset)\ntrain_dataset = train_dataset.transform()\n\ntrain_dataset = train_dataset[train_dataset['county'] != 12]\n\n### 2023/05/30 10am 이후로 weather 없음 --> drop\ntrain_dataset = train_dataset[~train_dataset['rain_historical'].isna()]","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:13:47.481653Z","iopub.execute_input":"2024-01-30T16:13:47.482360Z","iopub.status.idle":"2024-01-30T16:14:29.884863Z","shell.execute_reply.started":"2024-01-30T16:13:47.482314Z","shell.execute_reply":"2024-01-30T16:14:29.883561Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# NO MORE MISSING VALUES\n# train_dataset = train_dataset.fillna(method='bfill')\n# train_dataset = train_dataset.fillna(method='ffill')\n\ntrain_dataset = pd.get_dummies(train_dataset, drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:29.886444Z","iopub.execute_input":"2024-01-30T16:14:29.886835Z","iopub.status.idle":"2024-01-30T16:14:33.229914Z","shell.execute_reply.started":"2024-01-30T16:14:29.886805Z","shell.execute_reply":"2024-01-30T16:14:33.228575Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for col in train_dataset.columns:\n    if train_dataset[col].dtype == bool:\n        train_dataset[col] = train_dataset[col].astype(int)\n        \ntrain_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:33.231205Z","iopub.execute_input":"2024-01-30T16:14:33.231531Z","iopub.status.idle":"2024-01-30T16:14:34.790430Z","shell.execute_reply.started":"2024-01-30T16:14:33.231502Z","shell.execute_reply":"2024-01-30T16:14:34.789253Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        prediction_unit_id  day  weekday  month  year  sin(dayofyear)  \\\nrow_id                                                                  \n0                        0    1        3      9  2021       -0.866025   \n122                      0    1        3      9  2021       -0.866025   \n244                      0    1        3      9  2021       -0.866025   \n366                      0    1        3      9  2021       -0.866025   \n488                      0    1        3      9  2021       -0.866025   \n\n        cos(dayofyear)  sin(hour)  cos(hour)  eic_count  ...  segment_8_1_3_0  \\\nrow_id                                                   ...                    \n0                 -0.5   0.000000   1.000000      108.0  ...                0   \n122               -0.5   0.258819   0.965926      108.0  ...                0   \n244               -0.5   0.500000   0.866025      108.0  ...                0   \n366               -0.5   0.707107   0.707107      108.0  ...                0   \n488               -0.5   0.866025   0.500000      108.0  ...                0   \n\n        segment_8_1_3_1  segment_9_0_1_0  segment_9_0_1_1  segment_9_0_3_0  \\\nrow_id                                                                       \n0                     0                0                0                0   \n122                   0                0                0                0   \n244                   0                0                0                0   \n366                   0                0                0                0   \n488                   0                0                0                0   \n\n        segment_9_0_3_1  segment_9_1_1_0  segment_9_1_1_1  segment_9_1_3_0  \\\nrow_id                                                                       \n0                     0                0                0                0   \n122                   0                0                0                0   \n244                   0                0                0                0   \n366                   0                0                0                0   \n488                   0                0                0                0   \n\n        segment_9_1_3_1  \nrow_id                   \n0                     0  \n122                   0  \n244                   0  \n366                   0  \n488                   0  \n\n[5 rows x 238 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_unit_id</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>sin(dayofyear)</th>\n      <th>cos(dayofyear)</th>\n      <th>sin(hour)</th>\n      <th>cos(hour)</th>\n      <th>eic_count</th>\n      <th>...</th>\n      <th>segment_8_1_3_0</th>\n      <th>segment_8_1_3_1</th>\n      <th>segment_9_0_1_0</th>\n      <th>segment_9_0_1_1</th>\n      <th>segment_9_0_3_0</th>\n      <th>segment_9_0_3_1</th>\n      <th>segment_9_1_1_0</th>\n      <th>segment_9_1_1_1</th>\n      <th>segment_9_1_3_0</th>\n      <th>segment_9_1_3_1</th>\n    </tr>\n    <tr>\n      <th>row_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2021</td>\n      <td>-0.866025</td>\n      <td>-0.5</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2021</td>\n      <td>-0.866025</td>\n      <td>-0.5</td>\n      <td>0.258819</td>\n      <td>0.965926</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2021</td>\n      <td>-0.866025</td>\n      <td>-0.5</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2021</td>\n      <td>-0.866025</td>\n      <td>-0.5</td>\n      <td>0.707107</td>\n      <td>0.707107</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2021</td>\n      <td>-0.866025</td>\n      <td>-0.5</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 238 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset['transit_usage_estimate_0'][0]\ntrain_dataset['charging_access_estimate_0'][0]\ntrain_dataset['transit_usage_estimate_1'][0]\ntrain_dataset['charging_access_estimate_1'][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:34.791859Z","iopub.execute_input":"2024-01-30T16:14:34.792273Z","iopub.status.idle":"2024-01-30T16:14:34.994863Z","shell.execute_reply.started":"2024-01-30T16:14:34.792233Z","shell.execute_reply":"2024-01-30T16:14:34.993603Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"733.8396950987408"},"metadata":{}}]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"df_train_features = train_dataset[train_dataset['target'].notnull()]\nclean_memory()\ndf_train_features.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:34.996321Z","iopub.execute_input":"2024-01-30T16:14:34.996763Z","iopub.status.idle":"2024-01-30T16:14:39.278284Z","shell.execute_reply.started":"2024-01-30T16:14:34.996706Z","shell.execute_reply":"2024-01-30T16:14:39.276972Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1982992 entries, 0 to 2013529\nColumns: 238 entries, prediction_unit_id to segment_9_1_3_1\ndtypes: float32(65), float64(7), int32(1), int64(162), int8(3)\nmemory usage: 3.1 GB\n","output_type":"stream"}]},{"cell_type":"code","source":"LR_START = 1e-7\nLR_MAX = 1e-3\nLR_MIN = 1e-7\nLR_RAMPUP_EPOCHS = 2\nLR_SUSTAIN_EPOCHS = 2\nEPOCHS = 20\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        phase = math.pi * decay_epoch_index / decay_total_epochs\n        cosine_decay = 0.5 * (1 + math.cos(phase))\n        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n    \n    return lr\n\nrng = [i for i in range(EPOCHS)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(6,3))\nplt.plot(rng, lr_y, '-o')\nplt.xlabel('Epoch'); plt.ylabel('LR')\nprint('Learning Rate schedule : {:.3g} to {:3g} to {:3g}' . \\\n        format(lr_y[0], max(lr_y), lr_y[-1]))\nLR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:39.282243Z","iopub.execute_input":"2024-01-30T16:14:39.282600Z","iopub.status.idle":"2024-01-30T16:14:39.610567Z","shell.execute_reply.started":"2024-01-30T16:14:39.282570Z","shell.execute_reply":"2024-01-30T16:14:39.609718Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Learning Rate schedule : 1e-07 to 0.001 to 1e-07\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x300 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n# def preprocess_cat(df):\n#     df.county = df.county.astype(int)\n#     df.is_business = df.is_business.astype(int)\n#     df.product_type = df.product_type.astype(int)\n#     df.is_consumption = df.is_consumption.astype(int)\n#     df.segment = df.segment.astype(int)\n#     return df","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:39.611903Z","iopub.execute_input":"2024-01-30T16:14:39.612765Z","iopub.status.idle":"2024-01-30T16:14:40.074041Z","shell.execute_reply.started":"2024-01-30T16:14:39.612712Z","shell.execute_reply":"2024-01-30T16:14:40.070678Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# class Model:\n#     def __init__(self):\n#         self.conf = ModelConfig(auto_imputation=True,\n#                                 auto_discrete=True,\n#                                 auto_discard_unique=True,\n#                                 categorical_columns='auto',\n#                                 fixed_embedding_dim=False,\n#                                 embeddings_output_dim=4,\n#                                 embedding_dropout=0.3,\n#                                 nets=['dnn_nets'],\n#                                 dnn_params={\n#                                     'hidden_units': ((512, 0.3, True),\n#                                                      (256, 0.3, True)),\n#                                     'dnn_activation': 'relu',\n#                                 },\n#                                 stacking_op='add',\n#                                 output_use_bias=False,\n#                                 optimizer=CFG.optimizer,\n#                                 task='regression',\n#                                 loss='MeanAbsoluteError',\n#                                 metrics='MeanAbsoluteError',\n#                                 earlystopping_patience=1,\n#                                 )\n        \n#         self.lgb_params = {\"n_estimators\": 2500,\n#                            \"learning_rate\": 0.06,\n#                            \"max_depth\": 16,\n#                            \"num_leaves\": 500,\n#                            \"reg_alpha\": 3.5,\n#                            \"reg_lambda\": 1.5,\n#                            \"colsample_bytree\": 0.9,\n#                            \"colsample_bynode\": 0.6,\n#                            \"min_child_samples\": 50,\n#                            \"random_state\": 0,\n#                            \"objective\": \"regression_l1\",\n#                            \"device\": \"gpu\",\n#                            \"n_jobs\": 4,\n#                            \"verbose\": 1,\n#                            }\n        \n#         ### add\n#         self.cb_params = {\"colsample_bylevel\": 0.878,\n#                           \"task_type\": \"CPU\",\n#                           \"reg_lambda\": 3.438,\n#                           \"learning_rate\": 0.042,\n#                           \"max_depth\": 10,\n#                           \"min_data_in_leaf\": 50,\n#                           \"n_estimators\": 2500,\n#                           \"verbose\": 1,\n#                           \"objective\": 'MAE',\n#                           \"random_state\": 0\n#                          }\n        \n#         self.nn_model_consumption = DeepTable(config=self.conf)  \n#         self.nn_model_production = DeepTable(config=self.conf)\n        \n#         self.lgb_model_consumption = lgb.LGBMRegressor(**self.lgb_params)\n#         self.lgb_model_production = lgb.LGBMRegressor(**self.lgb_params)\n        \n#         self.cb_model_consumption = CatBoostRegressor(**self.cb_params)\n#         self.cb_model_production = CatBoostRegressor(**self.cb_params)\n        \n\n#     def fit(self, df_train_features):\n#         print('nn = '+str(CFG.nn))\n#         print('lgb = '+str(CFG.lgb))\n#         print('cb = '+str(CFG.cb))\n        \n#         if CFG.nn == True:\n            \n#             print('\\n',\"nn model consumption training.\",'\\n')\n#             mask = df_train_features[\"is_consumption_1\"] == 1\n#             self.nn_model_consumption.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#                 validation_split=CFG.valid_size, shuffle=False,\n#                 batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n#                 callbacks=CFG.LR_Scheduler\n#             )\n        \n#             # Avoid saving error\n#             with K.name_scope(CFG.optimizer.__class__.__name__):\n#                 for i, var in enumerate(CFG.optimizer.weights):\n#                     name = 'variable{}'.format(i)\n#                     CFG.optimizer.weights[i] = tf.Variable(var, name=name)\n#             self.conf = self.conf._replace(optimizer=CFG.optimizer)   \n#             self.nn_model_production = DeepTable(config=self.conf)\n            \n#             print('\\n',\"nn model production training.\",'\\n')\n#             mask = df_train_features[\"is_consumption_1\"] == 0\n#             self.nn_model_production.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#                 validation_split=CFG.valid_size, shuffle=False,\n#                 batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n#                 callbacks=CFG.LR_Scheduler\n#             )\n        \n#         if CFG.lgb == True:\n            \n#             print('\\n',\"lgb model consumption training.\")\n#             mask = df_train_features[\"is_consumption_1\"] == 1\n#             self.lgb_model_consumption.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#             )\n        \n#             print('\\n',\"lgb model production training.\",'\\n')\n#             mask = df_train_features[\"is_consumption_1\"] == 0\n#             self.lgb_model_production.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#             )\n        \n#         ### add\n#         if CFG.cb == True:\n            \n# #             df_train_features = preprocess_cat(df_train_features.copy())\n            \n#             print('\\n',\"cb model consumption training.\")\n#             mask = df_train_features[\"is_consumption_1\"] == 1\n#             self.cb_model_consumption.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#             )\n        \n#             print('\\n',\"cb model production training.\",'\\n')\n#             mask = df_train_features[\"is_consumption_1\"] == 0\n#             self.cb_model_production.fit(\n#                 X=df_train_features[mask].drop(columns=[\"target\"]),\n#                 y=df_train_features[mask][\"target\"],\n#             )\n\n#     def predict(self, df_features):\n#         predictions = np.zeros(len(df_features))\n#         print(df_features.shape)\n        \n#         if df_features.ndim == 2:\n#             mask_cons = (df_features[\"is_consumption_1\"] == 1).values\n#             mask_prod = (df_features[\"is_consumption_1\"] == 0).values\n        \n#             try:\n#                 assert CFG.nn == True and CFG.lgb == True and CFG.cb == True, \"At least one of models doesn't exist: [nn, lgb, cb]\"\n#                 print('\\n',\"nn & lgb & cb model consumption prediction.\",'\\n')\n#                 predictions[mask_cons] = np.clip(\n#                     CFG.ens_weights['nn'] * (self.nn_model_consumption.predict(df_features[mask_cons])[:,0])\n#                     + CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features[mask_cons]))\n#                     + CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features[mask_cons])),\n#                     0, np.inf,)\n#                 print('\\n',\"nn & lgb & cb model production prediction.\",'\\n')\n#                 predictions[mask_prod] = np.clip(\n#                     CFG.ens_weights['nn'] * (self.nn_model_production.predict(df_features[mask_prod])[:,0])\n#                     + CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features[mask_prod]))\n#                     + CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features[mask_prod])),\n#                     0, np.inf,)\n\n#             except Exception as error:\n#                 print(\"An error occurred:\", type(error).__name__, \"–\", error)\n#                 ##### 임시 코드 (디버깅용)\n#                 if CFG.nn + CFG.lgb + CFG.cb == 1:\n#                     CFG.ens_weights = {'nn': 1.0, 'lgb': 1.0, 'cb': 1.0}\n#                 elif CFG.nn + CFG.lgb + CFG.cb == 2:\n#                     CFG.ens_weights = {'nn': 0.5, 'lgb': 0.5, 'cb': 0.5}\n#                 #####\n#                 if CFG.nn == True:\n#                     print('\\n',\"nn model consumption prediction.\",'\\n')\n#                     predictions[mask_cons] += np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_consumption.predict(df_features[mask_cons])[:,0]),\n#                         0, np.inf,)\n#                     print('\\n',\"nn model production prediction.\",'\\n')\n#                     predictions[mask_prod] += np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_production.predict(df_features[mask_prod])[:,0]),\n#                         0, np.inf,)\n#                 if CFG.lgb == True:\n#                     print('\\n',\"lgb model consumption prediction.\",'\\n')\n#                     predictions[mask_cons] += np.clip(\n#                         CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features[mask_cons])),\n#                         0, np.inf,)\n#                     print('\\n',\"lgb model production prediction.\",'\\n')\n#                     predictions[mask_prod] += np.clip(\n#                         CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features[mask_prod])),\n#                         0, np.inf,)\n#                 if CFG.cb == True:\n#                     print('\\n',\"cb model consumption prediction.\",'\\n')\n#                     predictions[mask_cons] += np.clip(\n#                         CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features[mask_cons])),\n#                         0, np.inf,)\n#                     print('\\n',\"cb model production prediction.\",'\\n')\n#                     predictions[mask_prod] += np.clip(\n#                         CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features[mask_prod])),\n#                         0, np.inf,)                \n        \n        \n#         else: #\n#             mask = df_features[\"is_consumption_1\"] == 1 #is_consumption\n#             try:\n#                 assert CFG.nn == True and CFG.lgb == True and CFG.cb == True, \"At least one of models doesn't exist: [nn, lgb, cb]\"\n                \n#                 if mask == True:\n#                     print('\\n',\"nn & lgb & cb model consumption prediction.\",'\\n')\n#                     predictions = np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_consumption.predict(df_features))\n#                         + CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features))\n#                         + CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features)),\n#                         0, np.inf,)\n#                 else:\n#                     print('\\n',\"nn & lgb & cb model production prediction.\",'\\n')\n#                     predictions = np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_production.predict(df_features))\n#                         + CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features))\n#                         + CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features)),\n#                         0, np.inf,)\n\n#             except Exception as error:\n#                 print(\"An error occurred:\", type(error).__name__, \"–\", error)\n#                 ##### 임시 코드 (디버깅용)\n#                 if CFG.nn + CFG.lgb + CFG.cb == 1:\n#                     CFG.ens_weights = {'nn': 1.0, 'lgb': 1.0, 'cb': 1.0}\n#                 elif CFG.nn + CFG.lgb + CFG.cb == 2:\n#                     CFG.ens_weights = {'nn': 0.5, 'lgb': 0.5, 'cb': 0.5}\n#                 #####\n#                 if CFG.nn == True:\n#                     print('\\n',\"nn model consumption prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_consumption.predict(df_features)),\n#                         0, np.inf,)\n#                     print('\\n',\"nn model production prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['nn'] * (self.nn_model_production.predict(df_features)),\n#                         0, np.inf,)\n#                 if CFG.lgb == True:\n#                     print('\\n',\"lgb model consumption prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features)),\n#                         0, np.inf,)\n#                     print('\\n',\"lgb model production prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features)),\n#                         0, np.inf,)\n#                 if CFG.cb == True:\n#                     print('\\n',\"cb model consumption prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features)),\n#                         0, np.inf,)\n#                     print('\\n',\"cb model production prediction.\",'\\n')\n#                     predictions += np.clip(\n#                         CFG.ens_weights['cb'] * (self.cb_model_consumption.predict(df_features)),\n#                         0, np.inf,)  \n        \n        \n#         return predictions\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.076437Z","iopub.execute_input":"2024-01-30T16:14:40.077340Z","iopub.status.idle":"2024-01-30T16:14:40.097584Z","shell.execute_reply.started":"2024-01-30T16:14:40.077289Z","shell.execute_reply":"2024-01-30T16:14:40.096446Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Model:\n    def __init__(self):\n        self.conf = ModelConfig(auto_imputation=True,\n                                auto_discrete=True,\n                                auto_discard_unique=True,\n                                categorical_columns='auto',\n                                fixed_embedding_dim=False,\n                                embeddings_output_dim=4,\n                                embedding_dropout=0.3,\n                                nets=['dnn_nets'],\n                                dnn_params={\n                                    'hidden_units': ((512, 0.3, True),\n                                                     (256, 0.3, True)),\n                                    'dnn_activation': 'relu',\n                                },\n                                stacking_op='add',\n                                output_use_bias=False,\n                                optimizer=CFG.optimizer,\n                                task='regression',\n                                loss='MeanAbsoluteError',\n                                metrics='MeanAbsoluteError',\n                                earlystopping_patience=1,\n                                )\n        \n        self.lgb_params = {\"n_estimators\": 2500,\n                           \"learning_rate\": 0.06,\n                           \"max_depth\": 16,\n                           \"num_leaves\": 500,\n                           \"reg_alpha\": 3.5,\n                           \"reg_lambda\": 1.5,\n                           \"colsample_bytree\": 0.9,\n                           \"colsample_bynode\": 0.6,\n                           \"min_child_samples\": 50,\n                           \"random_state\": 0,\n                           \"objective\": \"regression_l1\",\n                           \"device\": \"gpu\",\n                           \"n_jobs\": 4,\n                           \"verbose\": 1,\n                           }\n        \n        ### add\n        self.cb_params = {\"colsample_bylevel\": 0.878,\n                          \"task_type\": \"CPU\",\n                          \"reg_lambda\": 3.438,\n                          \"learning_rate\": 0.042,\n                          \"max_depth\": 10,\n                          \"min_data_in_leaf\": 50,\n                          \"n_estimators\": 2500,\n                          \"verbose\": 1,\n                          \"objective\": 'MAE',\n                          \"random_state\": 0\n                         }\n        \n        self.nn_model_consumption = DeepTable(config=self.conf)  \n        self.nn_model_production = DeepTable(config=self.conf)\n        \n        self.lgb_model_consumption = lgb.LGBMRegressor(**self.lgb_params)\n        self.lgb_model_production = lgb.LGBMRegressor(**self.lgb_params)\n        \n        self.cb_model_consumption = CatBoostRegressor(**self.cb_params)\n        self.cb_model_production = CatBoostRegressor(**self.cb_params)\n        \n\n    def fit(self, df_train_features):\n        print('nn = '+str(CFG.nn))\n        print('lgb = '+str(CFG.lgb))\n        print('cb = '+str(CFG.cb))\n        \n        if CFG.nn == True:\n            \n            print('\\n',\"nn model consumption training.\",'\\n')\n            mask = df_train_features[\"is_consumption_1\"] == 1\n            self.nn_model_consumption.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n                validation_split=CFG.valid_size, shuffle=False,\n                batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n                callbacks=CFG.LR_Scheduler\n            )\n        \n            # Avoid saving error\n            with K.name_scope(CFG.optimizer.__class__.__name__):\n                for i, var in enumerate(CFG.optimizer.weights):\n                    name = 'variable{}'.format(i)\n                    CFG.optimizer.weights[i] = tf.Variable(var, name=name)\n            self.conf = self.conf._replace(optimizer=CFG.optimizer)   \n            self.nn_model_production = DeepTable(config=self.conf)\n            \n            print('\\n',\"nn model production training.\",'\\n')\n            mask = df_train_features[\"is_consumption_1\"] == 0\n            self.nn_model_production.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n                validation_split=CFG.valid_size, shuffle=False,\n                batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n                callbacks=CFG.LR_Scheduler\n            )\n        \n        if CFG.lgb == True:\n            \n            print('\\n',\"lgb model consumption training.\")\n            mask = df_train_features[\"is_consumption_1\"] == 1\n            self.lgb_model_consumption.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n            )\n        \n            print('\\n',\"lgb model production training.\",'\\n')\n            mask = df_train_features[\"is_consumption_1\"] == 0\n            self.lgb_model_production.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n            )\n        \n        ### add\n        if CFG.cb == True:\n            \n#             df_train_features = preprocess_cat(df_train_features.copy())\n            \n            print('\\n',\"cb model consumption training.\")\n            mask = df_train_features[\"is_consumption_1\"] == 1\n            self.cb_model_consumption.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n            )\n        \n            print('\\n',\"cb model production training.\",'\\n')\n            mask = df_train_features[\"is_consumption_1\"] == 0\n            self.cb_model_production.fit(\n                X=df_train_features[mask].drop(columns=[\"target\"]),\n                y=df_train_features[mask][\"target\"],\n            )\n\n    def predict(self, df_features):\n        predictions = np.zeros(len(df_features))\n        print('df_features.shape: ', df_features.shape)\n        print('predictions.shape: ', predictions.shape)\n        \n        mask_cons = (df_features[\"is_consumption_1\"] == 1).values\n        mask_prod = (df_features[\"is_consumption_1\"] == 0).values\n        print('mask shape:', mask_cons.shape, mask_prod.shape)\n        \n        print('\\n',\"lgb model consumption prediction.\",'\\n')\n        predictions[mask_cons] += np.clip(\n            CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features[mask_cons])),\n            0, np.inf,)\n        print('\\n',\"lgb model production prediction.\",'\\n')\n        predictions[mask_prod] += np.clip(\n            CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features[mask_prod])),\n            0, np.inf,)\n        \n        return predictions\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.099581Z","iopub.execute_input":"2024-01-30T16:14:40.100437Z","iopub.status.idle":"2024-01-30T16:14:40.134176Z","shell.execute_reply.started":"2024-01-30T16:14:40.100391Z","shell.execute_reply":"2024-01-30T16:14:40.132801Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    nn = False #True\n    lgb = True\n    cb = False #True\n    ens_weights = {'nn': 0.2, 'lgb': 0.4, 'cb': 0.4}\n    epochs = 20\n    batch_size = 512\n    valid_size = 5e-2\n    LR_Scheduler = [LR]\n    optimizer = AdamW(learning_rate=1e-3, weight_decay=9e-7)\n    \nmname = 'jw-0130'","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.136335Z","iopub.execute_input":"2024-01-30T16:14:40.137555Z","iopub.status.idle":"2024-01-30T16:14:40.160112Z","shell.execute_reply.started":"2024-01-30T16:14:40.137509Z","shell.execute_reply":"2024-01-30T16:14:40.158728Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# %%time\n# model = Model()\n# model.fit(df_train_features)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.162167Z","iopub.execute_input":"2024-01-30T16:14:40.163175Z","iopub.status.idle":"2024-01-30T16:14:40.183149Z","shell.execute_reply.started":"2024-01-30T16:14:40.163124Z","shell.execute_reply":"2024-01-30T16:14:40.181821Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# if CFG.nn == True:\n#     nn_model_consumption = model.nn_model_consumption.get_model().model\n#     nn_model_consumption.save(f'nn_model_consumption_{mname}.h5')\n#     nn_model_production = model.nn_model_production.get_model().model\n#     nn_model_production.save(f'nn_model_production_{mname}.h5')\n#     print('saved: DeepTable')\n    \n# if CFG.lgb == True:\n#     joblib.dump(model.lgb_model_consumption, f'lgb_model_consumption_{mname}.joblib')\n#     joblib.dump(model.lgb_model_production, f'lgb_model_production_{mname}.joblib')\n#     print('saved: LightGBM')\n    \n# if CFG.cb == True:\n#     model.cb_model_consumption.save_model(f'cb_model_consumption_{mname}', format='cbm')\n#     model.cb_model_production.save_model(f'cb_model_production_{mname}', format='cbm')\n#     print('saved: CatBoost')\n    \n\n# print(\"\\n DON'T FORGET TO DOWNLOAD TRAINED MODELS !!!!!!!!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.185099Z","iopub.execute_input":"2024-01-30T16:14:40.185876Z","iopub.status.idle":"2024-01-30T16:14:40.204534Z","shell.execute_reply.started":"2024-01-30T16:14:40.185833Z","shell.execute_reply":"2024-01-30T16:14:40.203267Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# clean_memory()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.206619Z","iopub.execute_input":"2024-01-30T16:14:40.207431Z","iopub.status.idle":"2024-01-30T16:14:40.217370Z","shell.execute_reply.started":"2024-01-30T16:14:40.207387Z","shell.execute_reply":"2024-01-30T16:14:40.216000Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Submit API","metadata":{}},{"cell_type":"code","source":"mdir = '/kaggle/input/enefit-first-submit-jw-test'\n# mdir = '/kaggle/working'\n\nmodel = Model()\n\nif CFG.lgb == True:\n    try:\n        model.lgb_model_consumption = joblib.load(f'{mdir}/lgb_model_consumption_{mname}.joblib')\n        model.lgb_model_production = joblib.load(f'{mdir}/lgb_model_production_{mname}.joblib')\n        print('pretrained model loaded: LightGBM')\n    except Exception as error:\n        print(\"An error occurred:\", type(error).__name__, \"–\", error)\n        print('load failed: LightGBM')\n\nif CFG.cb == True:\n    try:\n        model.cb_model_consumption = CatBoostRegressor()\n        model.cb_model_production = CatBoostRegressor()\n        model.cb_model_consumption.load_model(f'{mdir}/cb_model_consumption_{mname}')\n        model.cb_model_production.load_model(f'{mdir}/cb_model_production_{mname}')\n        print('pretrained model loaded: CatBoost')\n    except Exception as error:\n        print(\"An error occurred:\", type(error).__name__, \"–\", error)\n        print('load failed: CatBoost')\n\nfrom tensorflow.keras.models import load_model\nimport deeptables.models.layers\nif CFG.nn == True:\n    try:\n        model.nn_model_production = load_model(f'{mdir}/nn_model_production_{mname}.h5', custom_objects={'MultiColumnEmbedding':deeptables.models.layers.MultiColumnEmbedding})\n        model.nn_model_consumption = load_model(f'{mdir}/nn_model_consumption_{mname}.h5', custom_objects={'MultiColumnEmbedding':deeptables.models.layers.MultiColumnEmbedding})\n        print('pretrained model loaded: DeepTable')\n    except Exception as error:\n        print(\"An error occurred:\", type(error).__name__, \"–\", error)\n        print('load falied: DeepTable')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:40.219377Z","iopub.execute_input":"2024-01-30T16:14:40.220252Z","iopub.status.idle":"2024-01-30T16:14:45.608994Z","shell.execute_reply.started":"2024-01-30T16:14:40.220209Z","shell.execute_reply":"2024-01-30T16:14:45.607722Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"pretrained model loaded: LightGBM\n","output_type":"stream"}]},{"cell_type":"code","source":"# test_root = '/kaggle/working/'\n\n# df_data = pl.read_csv(\n#     os.path.join(test_root, \"test.csv\"),\n#     columns=data_cols,\n#     try_parse_dates=True,\n# )\n# df_client = pl.read_csv(\n#     os.path.join(test_root, \"client.csv\"),\n#     columns=client_cols,\n#     try_parse_dates=True,\n# )\n# df_gas_prices = pl.read_csv(\n#     os.path.join(test_root, \"gas_prices.csv\"),\n#     columns=gas_prices_cols,\n#     try_parse_dates=True,\n# )\n# df_electricity_prices = pl.read_csv(\n#     os.path.join(test_root, \"electricity_prices.csv\"),\n#     columns=electricity_prices_cols,\n#     try_parse_dates=True,\n# )\n# df_electricity_prices = self.df_electricity_prices.with_columns(\n#     df_electricity_prices['euros_per_mwh'].abs().alias('euros_per_mwh')\n# )\n# df_forecast_weather = pl.read_csv(\n#     os.path.join(test_root, \"forecast_weather.csv\"),\n#     columns=self.forecast_weather_cols,\n#     try_parse_dates=True,\n# )\n# self.df_historical_weather = pl.read_csv(\n#     os.path.join(test_root, \"historical_weather.csv\"),\n#     columns=self.historical_weather_cols,\n#     try_parse_dates=True,\n# )\n# self.df_weather_station_to_county_mapping = pl.read_csv(\n#     os.path.join(test_root, \"weather_station_to_county_mapping.csv\"),\n#     columns=self.location_cols,\n#     try_parse_dates=True,\n# )\n# self.df_target = self.df_data.select(self.target_cols)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:45.610523Z","iopub.execute_input":"2024-01-30T16:14:45.610979Z","iopub.status.idle":"2024-01-30T16:14:45.618264Z","shell.execute_reply.started":"2024-01-30T16:14:45.610938Z","shell.execute_reply":"2024-01-30T16:14:45.616976Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\n# data_storage.update_with_new_data(\n#     df_new_client=df_new_client,\n#     df_new_gas_prices=df_new_gas_prices,\n#     df_new_electricity_prices=df_new_electricity_prices,\n#     df_new_forecast_weather=df_new_forecast_weather,\n#     df_new_historical_weather=df_new_historical_weather,\n#     df_new_target=df_new_target\n# )\n# df_test = data_storage.preprocess_test(df_test)\n# df_test = data_storage.run_test()\n\n# df_test = features_generator.generate_features(df_test.df_data)\n# df_test = df_test[df_test['target'].notnull()]\n# df_test = add_custom_features(df_test)\n\n# df_test['eic_count'] = df_test['eic_count'].fillna(method = 'bfill')\n# df_test['installed_capacity'] = df_test['installed_capacity'].fillna(method = 'bfill')\n# df_test = DataTransformer(df_test)\n# df_test = df_test.transform()\n# df_test = TrainDataTransform(df_test)\n# df_test = df_test.transform()\n# df_test = df_test[df_test['county'] != 12]\n# df_test_features = df_test.fillna(method='bfill')\n# df_test_features = df_test_features.fillna(method='ffill')\n# df_test_features = df_test_features.drop(columns=['target'])\n# df_test_features = pd.get_dummies(df_test_features, drop_first=True)\n\n# for col in df_test_features.columns:\n#     if df_test_features[col].dtype == bool:\n#         df_test_features[col] = df_test_features[col].astype(int)\n\n# print('data preprocessed')\n# print(df_test_features.shape)\n# print(df_test_features[df_test_features['is_consumption_1']==1].shape)\n# print(df_test_features[df_test_features['is_consumption_1']==0].shape)\n\n# try:\n#     prec = model.predict(df_test_features)\n#     df_sample_prediction[\"target\"] = prec\n#     print('predicted and saved: ', df_sample_prediction.shape)\n\n# except Exception as error:\n#     print(\"An error occurred:\", type(error).__name__, \"–\", error)\n#     print('predict by rows')\n#     common_row_ids = df_test_features.index.intersection(df_sample_prediction['row_id'])\n\n#     data_row = df_test_features.loc[common_row_ids]\n#     test_prediction = model.predict(data_row)\n#     print('predicted: ', test_prediction.shape)\n\n#     for i, row_id in enumerate(common_row_ids):\n#         df_sample_prediction.loc[df_sample_prediction['row_id'] == row_id, 'target'] = test_prediction[i]\n#     print('prediction saved: ', df_sample_prediction.shape)\n# #         for row_id in common_row_ids:\n# #             data_row = df_test_features.loc[row_id]\n# #             test_prediction = model.predict(data_row)\n# #             df_sample_prediction.loc[df_sample_prediction['row_id'] == row_id, 'target'] = test_prediction[0]\n\n# print('prediction produced. env.predict...')\n\n# env.predict(df_sample_prediction)\n# clean_memory()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:45.619896Z","iopub.execute_input":"2024-01-30T16:14:45.620329Z","iopub.status.idle":"2024-01-30T16:14:45.640284Z","shell.execute_reply.started":"2024-01-30T16:14:45.620291Z","shell.execute_reply":"2024-01-30T16:14:45.639049Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import enefit\n\nenv = enefit.make_env()\niter_test = env.iter_test()\n\ndef is_prediciton_needed(df_test):\n     return not all(df_test['currently_scored'] == False)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:45.642108Z","iopub.execute_input":"2024-01-30T16:14:45.642557Z","iopub.status.idle":"2024-01-30T16:14:45.683564Z","shell.execute_reply.started":"2024-01-30T16:14:45.642516Z","shell.execute_reply":"2024-01-30T16:14:45.682364Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"mname","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:45.687700Z","iopub.execute_input":"2024-01-30T16:14:45.689077Z","iopub.status.idle":"2024-01-30T16:14:45.697270Z","shell.execute_reply.started":"2024-01-30T16:14:45.689026Z","shell.execute_reply":"2024-01-30T16:14:45.695979Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'jw-0130'"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nfor i, (\n    test, \n    df_new_target, \n    df_new_client, \n    df_new_historical_weather,\n    df_new_forecast_weather, \n    df_new_electricity_prices, \n    df_new_gas_prices, \n    df_sample_prediction\n) in enumerate(iter_test):\n\n    data_storage.update_with_new_data(\n        df_new_client=df_new_client,\n        df_new_gas_prices=df_new_gas_prices,\n        df_new_electricity_prices=df_new_electricity_prices,\n        df_new_forecast_weather=df_new_forecast_weather,\n        df_new_historical_weather=df_new_historical_weather,\n        df_new_target=df_new_target\n    )\n\n#     df_test = df_test.merge(df_sample_prediction, how=\"left\", on=\"row_id\")\n\n        \n    df_test = data_storage.preprocess_test(test)\n    print(type(df_test), df_test.shape)\n#     print(df_test.shape)\n#     df_test = data_storage.run_test()\n    \n    df_test = features_generator.generate_features(df_test)\n    print(df_test.shape)\n    df_test = add_custom_features(df_test)\n    print(df_test.shape)\n\n    df_test['eic_count'] = df_test['eic_count'].fillna(method = 'bfill')\n    print(df_test.shape)\n    df_test['installed_capacity'] = df_test['installed_capacity'].fillna(method = 'bfill')\n    print(df_test.shape)\n    df_test = DataTransformer(df_test, isTrain=False)\n    df_test = df_test.transform()\n    print(df_test.shape)\n    df_test = TrainDataTransform(df_test)\n    df_test = df_test.transform()\n    print(df_test.shape)\n#     df_test = df_test[df_test['county'] != 12]   # length mismatch error...\n#     print(df_test.shape)\n    df_test_features = df_test.fillna(method='bfill')\n    print(df_test_features.shape)\n    df_test_features = df_test_features.fillna(method='ffill')\n    print(df_test_features.shape)\n#     df_test_features = df_test_features.drop(columns=['target'])\n#     print(df_test_features.shape)\n    df_test_features = pd.get_dummies(df_test_features, drop_first=True)\n    print(df_test_features.shape)\n    \n    for col in df_test_features.columns:\n        if df_test_features[col].dtype == bool:\n            df_test_features[col] = df_test_features[col].astype(int)\n            \n    print('missing columns: ', df_train_features.drop('target', axis=1).columns.difference(df_test_features.columns).values)\n    for col in df_train_features.drop('target', axis=1).columns.difference(df_test_features.columns).values:\n        df_test_features[col] = 0\n    \n    print('data preprocessed')\n    print(df_test_features.shape)\n    print(df_test_features[df_test_features['is_consumption_1']==1].shape)\n    print(df_test_features[df_test_features['is_consumption_1']==0].shape)\n    \n    print('df_new_target', df_new_target.shape)\n    \n#     try:\n#     if not is_prediciton_needed(test):\n#         print(\"all currently_scored set to False -> dummy Prediction\")\n#         df_sample_prediction['target'] = 0\n#         env.predict(df_sample_prediction)\n#         continue\n\n\n    prec = model.predict(df_test_features)\n    df_sample_prediction[\"target\"] = prec\n    print('predicted and saved: ', df_sample_prediction.shape)\n\n#     except Exception as error:\n#         print(\"An error occurred:\", type(error).__name__, \"–\", error)\n#         print('predict by rows')\n#         common_row_ids = df_test_features.index.intersection(df_sample_prediction['row_id'])\n        \n#         data_row = df_test_features.loc[common_row_ids]\n#         test_prediction = model.predict(data_row)\n#         print('predicted: ', test_prediction.shape)\n        \n#         for i, row_id in enumerate(common_row_ids):\n#             df_sample_prediction.loc[df_sample_prediction['row_id'] == row_id, 'target'] = test_prediction[i]\n#         print('prediction saved: ', df_sample_prediction.shape)\n#         for row_id in common_row_ids:\n#             data_row = df_test_features.loc[row_id]\n#             test_prediction = model.predict(data_row)\n#             df_sample_prediction.loc[df_sample_prediction['row_id'] == row_id, 'target'] = test_prediction[0]\n    \n    print('prediction produced. env.predict...')\n    env.predict(df_sample_prediction)\n    clean_memory()\n    print('next batch...')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:14:45.704546Z","iopub.execute_input":"2024-01-30T16:14:45.705592Z","iopub.status.idle":"2024-01-30T16:15:01.359819Z","shell.execute_reply.started":"2024-01-30T16:14:45.705532Z","shell.execute_reply":"2024-01-30T16:15:01.358860Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\nstart to update with new data..\ndf_new_client (66, 6)\ndf_new_gas_prices (1, 4)\ndf_new_electricity_prices (24, 3)\ndf_new_forecast_weather (5376, 17)\ndf_new_historical_weather (2688, 17)\ndf_new_target (3168, 8)\n\n\ndata_storage updated!\ndf_client (66, 6)\ndf_gas_prices (1, 3)\ndf_electricity_prices (24, 2)\ndf_forecast_weather (5376, 19)\ndf_historical_weather (2688, 17)\ndf_target (3168, 6)\n<class 'polars.dataframe.frame.DataFrame'> (3120, 7)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 82)\n(3120, 85)\n(3120, 85)\n(3120, 85)\n(3120, 229)\nmissing columns:  ['segment_10_1_2_0' 'segment_10_1_2_1' 'segment_11_0_2_0'\n 'segment_11_0_2_1' 'segment_11_1_2_0' 'segment_11_1_2_1'\n 'segment_7_0_2_0' 'segment_7_0_2_1']\ndata preprocessed\n(3120, 237)\n(1560, 237)\n(1560, 237)\ndf_new_target (3168, 8)\ndf_features.shape:  (3120, 237)\npredictions.shape:  (3120,)\nmask shape: (3120,) (3120,)\n\n lgb model consumption prediction. \n\n\n lgb model production prediction. \n\npredicted and saved:  (3120, 2)\nprediction produced. env.predict...\nnext batch...\nstart to update with new data..\ndf_new_client (66, 6)\ndf_new_gas_prices (1, 4)\ndf_new_electricity_prices (24, 3)\ndf_new_forecast_weather (5376, 17)\ndf_new_historical_weather (2688, 17)\ndf_new_target (3168, 8)\n\n\ndata_storage updated!\ndf_client (66, 6)\ndf_gas_prices (1, 3)\ndf_electricity_prices (24, 2)\ndf_forecast_weather (5376, 19)\ndf_historical_weather (2688, 17)\ndf_target (3168, 6)\n<class 'polars.dataframe.frame.DataFrame'> (3120, 7)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 82)\n(3120, 85)\n(3120, 85)\n(3120, 85)\n(3120, 229)\nmissing columns:  ['segment_10_1_2_0' 'segment_10_1_2_1' 'segment_11_0_2_0'\n 'segment_11_0_2_1' 'segment_11_1_2_0' 'segment_11_1_2_1'\n 'segment_7_0_2_0' 'segment_7_0_2_1']\ndata preprocessed\n(3120, 237)\n(1560, 237)\n(1560, 237)\ndf_new_target (3168, 8)\ndf_features.shape:  (3120, 237)\npredictions.shape:  (3120,)\nmask shape: (3120,) (3120,)\n\n lgb model consumption prediction. \n\n\n lgb model production prediction. \n\npredicted and saved:  (3120, 2)\nprediction produced. env.predict...\nnext batch...\nstart to update with new data..\ndf_new_client (65, 6)\ndf_new_gas_prices (1, 4)\ndf_new_electricity_prices (24, 3)\ndf_new_forecast_weather (5376, 17)\ndf_new_historical_weather (2688, 17)\ndf_new_target (3120, 8)\n\n\ndata_storage updated!\ndf_client (65, 6)\ndf_gas_prices (1, 3)\ndf_electricity_prices (24, 2)\ndf_forecast_weather (5376, 19)\ndf_historical_weather (2688, 17)\ndf_target (3120, 6)\n<class 'polars.dataframe.frame.DataFrame'> (3120, 7)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 82)\n(3120, 85)\n(3120, 85)\n(3120, 85)\n(3120, 229)\nmissing columns:  ['segment_10_1_2_0' 'segment_10_1_2_1' 'segment_11_0_2_0'\n 'segment_11_0_2_1' 'segment_11_1_2_0' 'segment_11_1_2_1'\n 'segment_7_0_2_0' 'segment_7_0_2_1']\ndata preprocessed\n(3120, 237)\n(1560, 237)\n(1560, 237)\ndf_new_target (3120, 8)\ndf_features.shape:  (3120, 237)\npredictions.shape:  (3120,)\nmask shape: (3120,) (3120,)\n\n lgb model consumption prediction. \n\n\n lgb model production prediction. \n\npredicted and saved:  (3120, 2)\nprediction produced. env.predict...\nnext batch...\nstart to update with new data..\ndf_new_client (65, 6)\ndf_new_gas_prices (1, 4)\ndf_new_electricity_prices (24, 3)\ndf_new_forecast_weather (5376, 17)\ndf_new_historical_weather (2688, 17)\ndf_new_target (3120, 8)\n\n\ndata_storage updated!\ndf_client (65, 6)\ndf_gas_prices (1, 3)\ndf_electricity_prices (24, 2)\ndf_forecast_weather (5376, 19)\ndf_historical_weather (2688, 17)\ndf_target (3120, 6)\n<class 'polars.dataframe.frame.DataFrame'> (3120, 7)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 75)\n(3120, 82)\n(3120, 85)\n(3120, 85)\n(3120, 85)\n(3120, 229)\nmissing columns:  ['segment_10_1_2_0' 'segment_10_1_2_1' 'segment_11_0_2_0'\n 'segment_11_0_2_1' 'segment_11_1_2_0' 'segment_11_1_2_1'\n 'segment_7_0_2_0' 'segment_7_0_2_1']\ndata preprocessed\n(3120, 237)\n(1560, 237)\n(1560, 237)\ndf_new_target (3120, 8)\ndf_features.shape:  (3120, 237)\npredictions.shape:  (3120,)\nmask shape: (3120,) (3120,)\n\n lgb model consumption prediction. \n\n\n lgb model production prediction. \n\npredicted and saved:  (3120, 2)\nprediction produced. env.predict...\nnext batch...\nCPU times: user 17.5 s, sys: 4.95 s, total: 22.5 s\nWall time: 15.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.read_csv('/kaggle/working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T16:15:09.106630Z","iopub.execute_input":"2024-01-30T16:15:09.107093Z","iopub.status.idle":"2024-01-30T16:15:09.127150Z","shell.execute_reply.started":"2024-01-30T16:15:09.107053Z","shell.execute_reply":"2024-01-30T16:15:09.125948Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"        row_id      target\n0      2005872    0.962481\n1      2005873  265.871250\n2      2005874    0.000000\n3      2005875    4.252208\n4      2005876    6.723187\n...        ...         ...\n12475  2018347   81.803658\n12476  2018348    0.025612\n12477  2018349   46.026654\n12478  2018350    0.983875\n12479  2018351   83.355509\n\n[12480 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2005872</td>\n      <td>0.962481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2005873</td>\n      <td>265.871250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2005874</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2005875</td>\n      <td>4.252208</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2005876</td>\n      <td>6.723187</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12475</th>\n      <td>2018347</td>\n      <td>81.803658</td>\n    </tr>\n    <tr>\n      <th>12476</th>\n      <td>2018348</td>\n      <td>0.025612</td>\n    </tr>\n    <tr>\n      <th>12477</th>\n      <td>2018349</td>\n      <td>46.026654</td>\n    </tr>\n    <tr>\n      <th>12478</th>\n      <td>2018350</td>\n      <td>0.983875</td>\n    </tr>\n    <tr>\n      <th>12479</th>\n      <td>2018351</td>\n      <td>83.355509</td>\n    </tr>\n  </tbody>\n</table>\n<p>12480 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# %%time\n# for (\n#     df_test, \n#     df_new_target, \n#     df_new_client, \n#     df_new_historical_weather,\n#     df_new_forecast_weather, /\n#     df_new_electricity_prices, \n#     df_new_gas_prices, \n#     df_sample_prediction\n# ) in iter_test:\n\n#     data_storage.update_with_new_data(\n#         df_new_client=df_new_client,\n#         df_new_gas_prices=df_new_gas_prices,\n#         df_new_electricity_prices=df_new_electricity_prices,\n#         df_new_forecast_weather=df_new_forecast_weather,\n#         df_new_historical_weather=df_new_historical_weather,\n#         df_new_target=df_new_target\n#     )\n#     df_test = data_storage.preprocess_test(df_test)\n#     df_test = data_storage.run_test()\n    \n#     df_test = features_generator.generate_features(df_test.df_data)\n#     df_test = df_test[df_test['target'].notnull()]\n#     df_test = add_custom_features(df_test)\n\n#     #이거 먼저 와야함, 예림 추가\n#     df_test['eic_count'] = df_test['eic_count'].fillna(method = 'bfill')\n#     df_test['installed_capacity'] = df_test['installed_capacity'].fillna(method = 'bfill')\n#     #add yelim\n#     df_test = DataTransformer(df_test)\n#     df_test = df_test.transform()\n#     #add joonyong\n#     df_test = TrainDataTransform(df_test)\n#     df_test = df_test.transform()\n#     ### drop county == 12 , yelim added ####\n#     df_test = df_test[df_test['county'] != 12]\n#     df_test_features = df_test.fillna(method='bfill')\n#     df_test_features = df_test_features.fillna(method='ffill')\n#     df_test_features = df_test_features.drop(columns=['target'])\n#     df_test_features = pd.get_dummies(df_test_features, drop_first=True)\n#     print(df_test_features.shape)\n    \n#     try:\n#         prec = model.predict(df_test_features)\n#         df_sample_prediction[\"target\"] = prec\n\n#     except:\n#         common_row_ids = df_test_features.index.intersection(df_sample_prediction['row_id'])\n#         for row_id in common_row_ids:\n#             data_row = df_test_features.loc[row_id]\n#             test_prediction = model.predict(data_row)#.values.reshape(1,-1))\n#             df_sample_prediction.loc[df_sample_prediction['row_id'] == row_id, 'target'] = test_prediction[0]\n    \n#     print('prediction produced')\n#     env.predict(df_sample_prediction)\n#     clean_memory()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/test.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/train.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}