{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.15.0\n",
      "DeepTables version: 0.2.6\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import polars as pl \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import holidays\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf, deeptables as dt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.python.keras import backend as K\n",
    "from deeptables.models import DeepTable, ModelConfig\n",
    "from deeptables.models import deepnets\n",
    "import joblib\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('DeepTables version:', dt.__version__)\n",
    "\n",
    "# large number of warnings in data processing step\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# fast ai libraries\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# constants\n",
    "SEED = 2024 # global seed for notebook\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 20\n",
    "\n",
    "#library from Yelim\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from addfunc_YL import DataTransformer\n",
    "from addfunc_JY import TrainDataTransform\n",
    "from addfunc_JY import DataStorageTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStorage:\n",
    "    \"\"\"\n",
    "    This class was copied out from:\n",
    "    https://www.kaggle.com/code/vitalykudelya/enefit-object-oriented-gbdt\n",
    "    \"\"\"\n",
    "    \n",
    "    root = \"/Data/home/limkim/Enefit\" #change\n",
    "\n",
    "    data_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "        \"row_id\",\n",
    "    ]\n",
    "    client_cols = [\n",
    "        \"product_type\",\n",
    "        \"county\",\n",
    "        \"eic_count\",\n",
    "        \"installed_capacity\",\n",
    "        \"is_business\",\n",
    "        \"date\",\n",
    "    ]\n",
    "    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n",
    "    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n",
    "    forecast_weather_cols = [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"hours_ahead\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"cloudcover_high\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_total\",\n",
    "        \"10_metre_u_wind_component\",\n",
    "        \"10_metre_v_wind_component\",\n",
    "        \"forecast_datetime\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"surface_solar_radiation_downwards\",\n",
    "        \"snowfall\",\n",
    "        \"total_precipitation\",\n",
    "    ]\n",
    "    historical_weather_cols = [\n",
    "        \"datetime\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"rain\",\n",
    "        \"snowfall\",\n",
    "        \"surface_pressure\",\n",
    "        \"cloudcover_total\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_high\",\n",
    "        \"windspeed_10m\",\n",
    "        \"winddirection_10m\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"diffuse_radiation\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ]\n",
    "    location_cols = [\"longitude\", \"latitude\", \"county\"]\n",
    "    target_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_data = pl.read_csv(\n",
    "            os.path.join(self.root, \"train.csv\"),\n",
    "            columns=self.data_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_client = pl.read_csv(\n",
    "            os.path.join(self.root, \"client.csv\"),\n",
    "            columns=self.client_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_gas_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"gas_prices.csv\"),\n",
    "            columns=self.gas_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_electricity_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"electricity_prices.csv\"),\n",
    "            columns=self.electricity_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_forecast_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"forecast_weather.csv\"),\n",
    "            columns=self.forecast_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_historical_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"historical_weather.csv\"),\n",
    "            columns=self.historical_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_weather_station_to_county_mapping = pl.read_csv(\n",
    "            os.path.join(self.root, \"weather_station_to_county_mapping.csv\"),\n",
    "            columns=self.location_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_data = self.df_data.filter(\n",
    "            pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n",
    "        )\n",
    "        self.df_target = self.df_data.select(self.target_cols)\n",
    "\n",
    "        self.schema_data = self.df_data.schema\n",
    "        self.schema_client = self.df_client.schema\n",
    "        self.schema_gas_prices = self.df_gas_prices.schema\n",
    "        self.schema_electricity_prices = self.df_electricity_prices.schema\n",
    "        self.schema_forecast_weather = self.df_forecast_weather.schema\n",
    "        self.schema_historical_weather = self.df_historical_weather.schema\n",
    "        self.schema_target = self.df_target.schema\n",
    "\n",
    "        self.df_weather_station_to_county_mapping = (\n",
    "            self.df_weather_station_to_county_mapping.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def update_with_new_data(\n",
    "        self,\n",
    "        df_new_client,\n",
    "        df_new_gas_prices,\n",
    "        df_new_electricity_prices,\n",
    "        df_new_forecast_weather,\n",
    "        df_new_historical_weather,\n",
    "        df_new_target,\n",
    "    ):\n",
    "        df_new_client = pl.from_pandas(\n",
    "            df_new_client[self.client_cols], schema_overrides=self.schema_client\n",
    "        )\n",
    "        df_new_gas_prices = pl.from_pandas(\n",
    "            df_new_gas_prices[self.gas_prices_cols],\n",
    "            schema_overrides=self.schema_gas_prices,\n",
    "        )\n",
    "        df_new_electricity_prices = pl.from_pandas(\n",
    "            df_new_electricity_prices[self.electricity_prices_cols],\n",
    "            schema_overrides=self.schema_electricity_prices,\n",
    "        )\n",
    "        df_new_forecast_weather = pl.from_pandas(\n",
    "            df_new_forecast_weather[self.forecast_weather_cols],\n",
    "            schema_overrides=self.schema_forecast_weather,\n",
    "        )\n",
    "        df_new_historical_weather = pl.from_pandas(\n",
    "            df_new_historical_weather[self.historical_weather_cols],\n",
    "            schema_overrides=self.schema_historical_weather,\n",
    "        )\n",
    "        df_new_target = pl.from_pandas(\n",
    "            df_new_target[self.target_cols], schema_overrides=self.schema_target\n",
    "        )\n",
    "\n",
    "        self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n",
    "            [\"date\", \"county\", \"is_business\", \"product_type\"]\n",
    "        )\n",
    "        self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n",
    "            [\"forecast_date\"]\n",
    "        )\n",
    "        self.df_electricity_prices = pl.concat(\n",
    "            [self.df_electricity_prices, df_new_electricity_prices]\n",
    "        ).unique([\"forecast_date\"])\n",
    "        self.df_forecast_weather = pl.concat(\n",
    "            [self.df_forecast_weather, df_new_forecast_weather]\n",
    "        ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n",
    "        self.df_historical_weather = pl.concat(\n",
    "            [self.df_historical_weather, df_new_historical_weather]\n",
    "        ).unique([\"datetime\", \"latitude\", \"longitude\"])\n",
    "        self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "        )\n",
    "\n",
    "    def preprocess_test(self, df_test):\n",
    "        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
    "        df_test = pl.from_pandas(\n",
    "            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n",
    "        )\n",
    "        return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGenerator:\n",
    "    \"\"\"\n",
    "    This class was copied out from:\n",
    "    https://www.kaggle.com/code/vitalykudelya/enefit-object-oriented-gbdt\n",
    "    \"\"\"\n",
    "    def __init__(self, data_storage):\n",
    "        self.data_storage = data_storage\n",
    "\n",
    "    def _add_general_features(self, df_features):\n",
    "        df_features = (\n",
    "            df_features.with_columns(\n",
    "                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "                pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "                pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_str(\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    separator=\"_\",\n",
    "                ).alias(\"segment\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "            )\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_client_features(self, df_features):\n",
    "        df_client = self.data_storage.df_client\n",
    "\n",
    "        df_features = df_features.join(\n",
    "            df_client.with_columns(\n",
    "                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n",
    "            ),\n",
    "            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_forecast_weather_features(self, df_features):\n",
    "        df_forecast_weather = self.data_storage.df_forecast_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_forecast_weather = (\n",
    "            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n",
    "            .filter((pl.col(\"hours_ahead\") >= 22) & pl.col(\"hours_ahead\") <= 45)\n",
    "            .drop(\"hours_ahead\")\n",
    "            .with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_date = (\n",
    "            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_local = (\n",
    "            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [0, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_historical_weather_features(self, df_features):\n",
    "        df_historical_weather = self.data_storage.df_historical_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_historical_weather = (\n",
    "            df_historical_weather.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_date = (\n",
    "            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_local = (\n",
    "            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [2 * 24, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [1 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag),\n",
    "                    pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                )\n",
    "                .filter(pl.col(\"hour\") <= 10)\n",
    "                .drop(\"hour\"),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_target_features(self, df_features):\n",
    "        df_target = self.data_storage.df_target\n",
    "\n",
    "        df_target_all_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\")\n",
    "        )\n",
    "\n",
    "        df_target_all_county_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\", \"county\")\n",
    "        )\n",
    "\n",
    "        for hours_lag in [\n",
    "            1 * 24,\n",
    "            2 * 24,\n",
    "            3 * 24,\n",
    "            4 * 24,\n",
    "            5 * 24,\n",
    "            6 * 24,\n",
    "            7 * 24,\n",
    "            8 * 24,\n",
    "            9 * 24,\n",
    "            10 * 24,\n",
    "            11 * 24,\n",
    "            12 * 24,\n",
    "            13 * 24,\n",
    "            14 * 24,\n",
    "        ]:\n",
    "            df_features = df_features.join(\n",
    "                df_target.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_{hours_lag}h\"}),\n",
    "                on=[\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    \"datetime\",\n",
    "                ],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_county_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_all_county_type_sum_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        cols_for_stats = [\n",
    "            f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n",
    "        ]\n",
    "        df_features = df_features.with_columns(\n",
    "            df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n",
    "            df_features.select(cols_for_stats)\n",
    "            .transpose()\n",
    "            .std()\n",
    "            .transpose()\n",
    "            .to_series()\n",
    "            .alias(f\"target_std\"),\n",
    "        )\n",
    "\n",
    "        for target_prefix, lag_nominator, lag_denomonator in [\n",
    "            (\"target\", 24 * 1, 24 * 2),\n",
    "            (\"target\", 24 * 2, 24 * 3),\n",
    "            (\"target\", 24 * 3, 24 * 4),\n",
    "            (\"target\", 24 * 4, 24 * 5),\n",
    "            (\"target\", 24 * 5, 24 * 6),\n",
    "            (\"target\", 24 * 6, 24 * 7),\n",
    "            (\"target\", 24 * 1, 24 * 7),\n",
    "            (\"target\", 24 * 1, 24 * 14),\n",
    "            (\"target\", 24 * 7, 24 * 14),\n",
    "            (\"target_all_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 7, 24 * 14),\n",
    "            (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n",
    "        ]:\n",
    "            df_features = df_features.with_columns(\n",
    "                (\n",
    "                    pl.col(f\"{target_prefix}_{lag_nominator}h\")\n",
    "                    / (pl.col(f\"{target_prefix}_{lag_denomonator}h\") + 1e-3)\n",
    "                ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denomonator}\")\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _reduce_memory_usage(self, df_features):\n",
    "        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n",
    "        return df_features\n",
    "\n",
    "    def _drop_columns(self, df_features):\n",
    "        df_features = df_features.drop(\n",
    "           \"datetime\", \"hour\", \"dayofyear\"\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _to_pandas(self, df_features, y):\n",
    "        cat_cols = [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "            \"segment\",\n",
    "        ]\n",
    "\n",
    "        if y is not None:\n",
    "            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n",
    "        else:\n",
    "            df_features = df_features.to_pandas()\n",
    "\n",
    "        df_features = df_features.set_index(\"row_id\")\n",
    "        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def generate_features(self, df_prediction_items):\n",
    "        if \"target\" in df_prediction_items.columns:\n",
    "            df_prediction_items, y = (\n",
    "                df_prediction_items.drop(\"target\"),\n",
    "                df_prediction_items.select(\"target\"),\n",
    "            )\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        df_features = df_prediction_items.with_columns(\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "        )\n",
    "\n",
    "        for add_features in [\n",
    "            self._add_general_features,\n",
    "            self._add_client_features,\n",
    "            self._add_forecast_weather_features,\n",
    "            self._add_historical_weather_features,\n",
    "            self._add_target_features,\n",
    "            self._reduce_memory_usage,\n",
    "            self._drop_columns,\n",
    "        ]:\n",
    "            df_features = add_features(df_features)\n",
    "\n",
    "        df_features = self._to_pandas(df_features, y)\n",
    "\n",
    "        return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2_dataloader(df):\n",
    "\n",
    "    # define categorical and continous numerical feature column names (on small number of features)\n",
    "    # from train.csv\n",
    "    cat_names = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"segment\"]\n",
    "    # from datetime column\n",
    "    cat_names += ['sin(dayofyear)', 'cos(dayofyear)', 'sin(hour)', 'cos(hour)']\n",
    "    # from https://www.kaggle.com/code/albansteff/enefit-estonian-holidays-lb-65-79 notebook\n",
    "    cat_names += ['country_holiday']\n",
    "    \n",
    "    # from client.csv\n",
    "    cont_names = [\"installed_capacity\", \"eic_count\"]\n",
    "    \n",
    "    # from forecast_weather.csv (next 0 hours)\n",
    "    cont_names += [_ for _ in df.columns if \"_forecast_0h\" in _]\n",
    "    cont_names += [_ for _ in df.columns if \"_forecast_local_0h\" in _]\n",
    "    # from forecast_weather.csv (next 24 hours)\n",
    "    cont_names += [_ for _ in df.columns if \"_forecast_24h\" in _]\n",
    "    cont_names += [_ for _ in df.columns if \"_forecast_local_24h\" in _]\n",
    "    \n",
    "    # from historical_weather.csv (last 24/48 hours)\n",
    "    cont_names += [_ for _ in df.columns if \"_historical_24h\" in _]\n",
    "    cont_names += [_ for _ in df.columns if \"_historical_48h\" in _]\n",
    "    cont_names += [_ for _ in df.columns if \"_historical_local_48h\" in _]\n",
    "    \n",
    "    # add all historical target values (last n hours)\n",
    "    cont_names += df.filter(regex=(\"target_.[0-9]*h\")).columns.tolist()\n",
    "    cont_names += ['target_mean', 'target_std']\n",
    "    \n",
    "    # add ratios between last kown target values\n",
    "    cont_names += df.filter(regex=(\"target_ratio_.[0-9]\")).columns.tolist()\n",
    "    \n",
    "    procs = [Categorify, FillMissing, Normalize]\n",
    "    \n",
    "    # log transform target variable\n",
    "    df.loc[:, 'target'] = np.log1p(df['target'])\n",
    "        \n",
    "    # convert pandas DataFrame to fastai DataLoader object\n",
    "    # code snippet taken from\n",
    "    # https://docs.fast.ai/tabular.learner.html\n",
    "    splits = RandomSplitter(valid_pct=0.2, seed = SEED)(df)\n",
    "    \n",
    "    # tabular object (only categorical features)\n",
    "    to = TabularPandas(df[cat_names + cont_names + [\"target\"]],\n",
    "                       procs = procs,\n",
    "                       cat_names = cat_names,\n",
    "                       cont_names = cont_names,\n",
    "                       y_names = [\"target\"],\n",
    "                       splits=splits)\n",
    "    # create dataloader\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dls = to.dataloaders(BATCH_SIZE, device = device)\n",
    "     \n",
    "    # return all dataloaders as tuple\n",
    "    return dls\n",
    "\n",
    "def add_custom_features(df):\n",
    "    \"\"\"\n",
    "    Function inspired by notebook:\n",
    "    https://www.kaggle.com/code/albansteff/enefit-estonian-holidays-lb-65-79\n",
    "    \"\"\"\n",
    "    \n",
    "    # code bellow same as in NB v17 add_holidays_as_binary_features function\n",
    "    estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\n",
    "    estonian_holidays = [pd.to_datetime(_) for _ in estonian_holidays.keys()]\n",
    "    \n",
    "    df['country_holiday'] = df['date'].isin(estonian_holidays) * 1\n",
    "    del df['date']\n",
    "    \n",
    "    # log transform histrocial target values\n",
    "    _cols = df.filter(regex=(\"target_.[0-9]*h\")).columns.tolist()\n",
    "    for _col in _cols:\n",
    "        df.loc[:, _col] = np.log1p(df[_col])        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_storage = DataStorage()\n",
    "features_generator = FeaturesGenerator(data_storage=data_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = features_generator.generate_features(data_storage.df_data)\n",
    "# exclude rows with missing target value\n",
    "train_dataset = train_dataset[train_dataset['target'].notnull()]\n",
    "# add estonian holidays\n",
    "train_dataset = add_custom_features(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add yelim\n",
    "train_dataset = DataTransformer(train_dataset)\n",
    "train_dataset = train_dataset.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.to_csv('/Data/home/limkim/Enefit/Kaggle2024_Enefit/baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1651902 entries, 366048 to 2018351\n",
      "Columns: 205 entries, county to charging_access_estimate_1\n",
      "dtypes: category(5), float32(162), float64(31), int32(1), int64(2), int8(3), object(1)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train_features = train_dataset[train_dataset['target'].notnull()]\n",
    "df_train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate schedule : 1e-07 to 0.001 to 1e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_START = 1e-7\n",
    "LR_MAX = 1e-3\n",
    "LR_MIN = 1e-7\n",
    "LR_RAMPUP_EPOCHS = 2\n",
    "LR_SUSTAIN_EPOCHS = 2\n",
    "EPOCHS = 20\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
    "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    \n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "lr_y = [lrfn(x) for x in rng]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(rng, lr_y, '-o')\n",
    "plt.xlabel('Epoch'); plt.ylabel('LR')\n",
    "print('Learning Rate schedule : {:.3g} to {:3g} to {:3g}' . \\\n",
    "        format(lr_y[0], max(lr_y), lr_y[-1]))\n",
    "LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn = True\n",
      "lgb = True\n",
      "\n",
      " nn model consumption training. \n",
      "\n",
      "01-22 16:28:17 I deeptables.m.deeptable.py 337 - X.Shape=(825951, 204), y.Shape=(825951,), batch_size=512, config=ModelConfig(name='conf-1', nets=['dnn_nets'], categorical_columns='auto', exclude_columns=[], task='regression', pos_label=None, metrics='MeanAbsoluteError', auto_categorize=False, cat_exponent=0.5, cat_remain_numeric=True, auto_encode_label=True, auto_imputation=True, auto_discrete=True, auto_discard_unique=True, apply_gbm_features=False, gbm_params={}, gbm_feature_type='embedding', fixed_embedding_dim=False, embeddings_output_dim=4, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_activity_regularizer=None, dense_dropout=0, embedding_dropout=0.3, stacking_op='add', output_use_bias=False, apply_class_weight=False, optimizer=<tensorflow_addons.optimizers.weight_decay_optimizers.AdamW object at 0x7f2482dc4a60>, loss='MeanAbsoluteError', dnn_params={'hidden_units': ((512, 0.3, True), (256, 0.3, True)), 'dnn_activation': 'relu'}, autoint_params={'num_attention': 3, 'num_heads': 1, 'dropout_rate': 0, 'use_residual': True}, fgcnn_params={'fg_filters': (14, 16), 'fg_heights': (7, 7), 'fg_pool_heights': (2, 2), 'fg_new_feat_filters': (2, 2)}, fibinet_params={'senet_pooling_op': 'mean', 'senet_reduction_ratio': 3, 'bilinear_type': 'field_interaction'}, cross_params={'num_cross_layer': 4}, pnn_params={'outer_product_kernel_type': 'mat'}, afm_params={'attention_factor': 4, 'dropout_rate': 0}, cin_params={'cross_layer_size': (128, 128), 'activation': 'relu', 'use_residual': False, 'use_bias': False, 'direct': False, 'reduce_D': False}, home_dir=None, monitor_metric=None, earlystopping_patience=1, earlystopping_mode='auto', gpu_usage_strategy='memory_growth', distribute_strategy=None, var_len_categorical_columns=None)\n",
      "01-22 16:28:17 I deeptables.m.deeptable.py 338 - metrics:MeanAbsoluteError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-22 16:28:18 W hypernets.t.cache.py 210 - AttributeError: Can't pickle local object 'make_gradient_clipnorm_fn.<locals>.<lambda>'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/cache.py\", line 165, in _cache_call\n",
      "    cache_key = tb.data_hasher()(key_items)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 20, in __call__\n",
      "    for x in self._iter_data(data):\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 58, in _iter_data\n",
      "    yield from self._iter_data(v)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 53, in _iter_data\n",
      "    yield from self._iter_data(x)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 61, in _iter_data\n",
      "    pickle.dump(data, buf, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-22 16:28:18 I deeptables.m.preprocessor.py 261 - Preparing features...\n",
      "01-22 16:28:20 I deeptables.m.preprocessor.py 336 - Preparing features taken 1.7317285537719727s\n",
      "01-22 16:28:20 I deeptables.m.preprocessor.py 341 - Data imputation...\n",
      "01-22 16:28:35 I deeptables.m.preprocessor.py 383 - Imputation taken 14.850428104400635s\n",
      "01-22 16:28:35 I deeptables.m.preprocessor.py 388 - Categorical encoding...\n",
      "01-22 16:28:36 I deeptables.m.preprocessor.py 393 - Categorical encoding taken 0.8660624027252197s\n",
      "01-22 16:28:36 I deeptables.m.preprocessor.py 398 - Data discretization...\n",
      "01-22 16:28:36 I hypernets.t.sklearn_ex.py 716 - 171 variables to discrete.\n",
      "01-22 16:29:00 I deeptables.m.preprocessor.py 404 - Discretization taken 23.721153736114502s\n",
      "01-22 16:29:08 I deeptables.m.preprocessor.py 196 - fit_transform taken 49.51470375061035s\n",
      "01-22 16:29:08 I deeptables.m.deeptable.py 353 - Training...\n",
      "01-22 16:29:08 I deeptables.m.deeptable.py 752 - Injected a callback [EarlyStopping]. monitor:val_m, patience:1, mode:min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:29:08.305359: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-22 16:29:10 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=512, shuffle=False, drop_remainder=True\n",
      "01-22 16:29:17 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=512, shuffle=False, drop_remainder=True\n",
      "01-22 16:29:18 I deeptables.m.deepmodel.py 231 - Building model...\n",
      "01-22 16:29:19 I deeptables.m.deepmodel.py 287 - >>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (176)', 'input_continuous_all: (171)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [18, 4, 6, 71, 4, 4, 4, 4, 3, 6, 6, 4, 4, 7, 8, 13, 13, 12, 13, 12, 12, 13, 13, 11, 11, 11, 12, 23, 22, 20, 20, 20, 20, 23, 23, 20, 20, 16, 19, 13, 13, 12, 13, 12, 12, 13, 13, 11, 11, 11, 12, 23, 22, 20, 20, 20, 20, 23, 23, 20, 20, 17, 19, 12, 12, 7, 7, 12, 11, 11, 11, 11, 12, 12, 11, 11, 11, 11, 10, 6, 6, 12, 8, 8, 8, 8, 10, 10, 12, 11, 10, 12, 12, 7, 7, 12, 11, 11, 11, 11, 12, 12, 11, 11, 11, 11, 10, 6, 6, 12, 8, 8, 8, 8, 10, 10, 12, 11, 10, 10, 10, 7, 6, 11, 10, 10, 10, 10, 10, 10, 9, 9, 9, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 26, 15, 26, 15, 26, 14, 26, 14, 30, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27, 26, 15, 14, 3, 3, 13, 32, 13, 32]\n",
      "output_dims: [8, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 4, 8, 4, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 8, 4, 8]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 1111)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 1111), output_shape (None, 256)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: None, output_shape: (None, 1), use_bias: False\n",
      "loss: MeanAbsoluteError\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "01-22 16:29:19 I deeptables.m.deepmodel.py 105 - training...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 46s - loss: 239.7784 - mean_absolute_error: 239.7784 - val_loss: 76.3279 - val_mean_absolute_error: 76.3279 - 46s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 74.7288 - mean_absolute_error: 74.7288 - val_loss: 42.1380 - val_mean_absolute_error: 42.1380 - 28s/epoch - 18ms/step\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 66.5320 - mean_absolute_error: 66.5320 - val_loss: 37.5091 - val_mean_absolute_error: 37.5091 - 28s/epoch - 18ms/step\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 63.7240 - mean_absolute_error: 63.7240 - val_loss: 35.8536 - val_mean_absolute_error: 35.8536 - 28s/epoch - 18ms/step\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 61.8383 - mean_absolute_error: 61.8383 - val_loss: 33.5582 - val_mean_absolute_error: 33.5582 - 28s/epoch - 18ms/step\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 60.4592 - mean_absolute_error: 60.4592 - val_loss: 32.1848 - val_mean_absolute_error: 32.1848 - 28s/epoch - 18ms/step\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 59.3885 - mean_absolute_error: 59.3885 - val_loss: 32.2273 - val_mean_absolute_error: 32.2273 - 28s/epoch - 18ms/step\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 58.6000 - mean_absolute_error: 58.6000 - val_loss: 31.2172 - val_mean_absolute_error: 31.2172 - 28s/epoch - 18ms/step\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 57.7065 - mean_absolute_error: 57.7065 - val_loss: 30.0775 - val_mean_absolute_error: 30.0775 - 28s/epoch - 18ms/step\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 28s - loss: 57.1763 - mean_absolute_error: 57.1763 - val_loss: 31.2054 - val_mean_absolute_error: 31.2054 - 28s/epoch - 18ms/step\n",
      "01-22 16:34:16 I deeptables.m.deepmodel.py 122 - Training finished.\n",
      "01-22 16:34:16 I deeptables.m.deeptable.py 369 - Training finished.\n",
      "01-22 16:34:16 I deeptables.m.deeptable.py 704 - Model has been saved to:dt_output/dt_20240122162815_dnn_nets/dnn_nets.h5\n",
      "\n",
      " nn model production training. \n",
      "\n",
      "01-22 16:34:18 I deeptables.m.deeptable.py 337 - X.Shape=(825951, 204), y.Shape=(825951,), batch_size=512, config=ModelConfig(name='conf-1', nets=['dnn_nets'], categorical_columns='auto', exclude_columns=[], task='regression', pos_label=None, metrics='MeanAbsoluteError', auto_categorize=False, cat_exponent=0.5, cat_remain_numeric=True, auto_encode_label=True, auto_imputation=True, auto_discrete=True, auto_discard_unique=True, apply_gbm_features=False, gbm_params={}, gbm_feature_type='embedding', fixed_embedding_dim=False, embeddings_output_dim=4, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_activity_regularizer=None, dense_dropout=0, embedding_dropout=0.3, stacking_op='add', output_use_bias=False, apply_class_weight=False, optimizer=<tensorflow_addons.optimizers.weight_decay_optimizers.AdamW object at 0x7f2482dc4a60>, loss='MeanAbsoluteError', dnn_params={'hidden_units': ((512, 0.3, True), (256, 0.3, True)), 'dnn_activation': 'relu'}, autoint_params={'num_attention': 3, 'num_heads': 1, 'dropout_rate': 0, 'use_residual': True}, fgcnn_params={'fg_filters': (14, 16), 'fg_heights': (7, 7), 'fg_pool_heights': (2, 2), 'fg_new_feat_filters': (2, 2)}, fibinet_params={'senet_pooling_op': 'mean', 'senet_reduction_ratio': 3, 'bilinear_type': 'field_interaction'}, cross_params={'num_cross_layer': 4}, pnn_params={'outer_product_kernel_type': 'mat'}, afm_params={'attention_factor': 4, 'dropout_rate': 0}, cin_params={'cross_layer_size': (128, 128), 'activation': 'relu', 'use_residual': False, 'use_bias': False, 'direct': False, 'reduce_D': False}, home_dir=None, monitor_metric=None, earlystopping_patience=1, earlystopping_mode='auto', gpu_usage_strategy='memory_growth', distribute_strategy=None, var_len_categorical_columns=None)\n",
      "01-22 16:34:18 I deeptables.m.deeptable.py 338 - metrics:MeanAbsoluteError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-22 16:34:19 W hypernets.t.cache.py 210 - AttributeError: Can't pickle local object 'make_gradient_clipnorm_fn.<locals>.<lambda>'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/cache.py\", line 165, in _cache_call\n",
      "    cache_key = tb.data_hasher()(key_items)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 20, in __call__\n",
      "    for x in self._iter_data(data):\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 58, in _iter_data\n",
      "    yield from self._iter_data(v)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 53, in _iter_data\n",
      "    yield from self._iter_data(x)\n",
      "  File \"/Data/home/limkim/anaconda3/lib/python3.9/site-packages/hypernets/tabular/data_hasher.py\", line 61, in _iter_data\n",
      "    pickle.dump(data, buf, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-22 16:34:19 I deeptables.m.preprocessor.py 261 - Preparing features...\n",
      "01-22 16:34:21 I deeptables.m.preprocessor.py 336 - Preparing features taken 1.5091071128845215s\n",
      "01-22 16:34:21 I deeptables.m.preprocessor.py 341 - Data imputation...\n",
      "01-22 16:34:35 I deeptables.m.preprocessor.py 383 - Imputation taken 14.517640590667725s\n",
      "01-22 16:34:35 I deeptables.m.preprocessor.py 388 - Categorical encoding...\n",
      "01-22 16:34:36 I deeptables.m.preprocessor.py 393 - Categorical encoding taken 0.85685133934021s\n",
      "01-22 16:34:36 I deeptables.m.preprocessor.py 398 - Data discretization...\n",
      "01-22 16:34:36 I hypernets.t.sklearn_ex.py 716 - 172 variables to discrete.\n",
      "01-22 16:34:58 I deeptables.m.preprocessor.py 404 - Discretization taken 21.821974515914917s\n",
      "01-22 16:35:05 I deeptables.m.preprocessor.py 196 - fit_transform taken 46.03046536445618s\n",
      "01-22 16:35:05 I deeptables.m.deeptable.py 353 - Training...\n",
      "01-22 16:35:07 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=512, shuffle=False, drop_remainder=True\n",
      "01-22 16:35:11 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=512, shuffle=False, drop_remainder=True\n",
      "01-22 16:35:11 I deeptables.m.deepmodel.py 231 - Building model...\n",
      "01-22 16:35:11 I deeptables.m.deepmodel.py 287 - >>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (177)', 'input_continuous_all: (172)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [18, 4, 6, 71, 4, 4, 4, 4, 3, 6, 6, 4, 4, 7, 8, 13, 13, 12, 13, 12, 12, 13, 13, 11, 11, 11, 12, 23, 22, 20, 20, 20, 20, 23, 23, 20, 20, 16, 19, 13, 13, 12, 13, 12, 12, 13, 13, 11, 11, 11, 12, 23, 22, 20, 20, 20, 20, 23, 23, 20, 20, 17, 19, 12, 12, 7, 7, 12, 11, 11, 11, 11, 12, 12, 11, 11, 11, 11, 10, 6, 6, 12, 8, 8, 8, 8, 10, 10, 12, 11, 10, 12, 12, 7, 7, 12, 11, 11, 11, 11, 12, 12, 11, 11, 11, 11, 10, 6, 6, 12, 8, 8, 8, 8, 10, 10, 12, 11, 10, 10, 10, 7, 6, 11, 10, 10, 10, 10, 10, 10, 9, 9, 9, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 21, 14, 21, 14, 21, 14, 21, 14, 25, 29, 28, 28, 28, 28, 28, 28, 28, 28, 28, 24, 24, 15, 14, 3, 3, 13, 32, 13, 12, 32]\n",
      "output_dims: [8, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 4, 8, 4, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 8, 4, 4, 8]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 1116)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 1116), output_shape (None, 256)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: None, output_shape: (None, 1), use_bias: False\n",
      "loss: MeanAbsoluteError\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "01-22 16:35:11 I deeptables.m.deepmodel.py 105 - training...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 43s - loss: 35.5868 - mean_absolute_error: 35.5868 - val_loss: 22.0400 - val_mean_absolute_error: 22.0400 - 43s/epoch - 28ms/step\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 27.8587 - mean_absolute_error: 27.8587 - val_loss: 17.8600 - val_mean_absolute_error: 17.8600 - 26s/epoch - 17ms/step\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 25.7959 - mean_absolute_error: 25.7959 - val_loss: 16.2909 - val_mean_absolute_error: 16.2909 - 26s/epoch - 17ms/step\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 23.7927 - mean_absolute_error: 23.7927 - val_loss: 15.5140 - val_mean_absolute_error: 15.5140 - 26s/epoch - 17ms/step\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 22.1215 - mean_absolute_error: 22.1215 - val_loss: 14.7455 - val_mean_absolute_error: 14.7455 - 26s/epoch - 17ms/step\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 20.7658 - mean_absolute_error: 20.7658 - val_loss: 14.1554 - val_mean_absolute_error: 14.1554 - 26s/epoch - 17ms/step\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 19.6481 - mean_absolute_error: 19.6481 - val_loss: 13.9097 - val_mean_absolute_error: 13.9097 - 26s/epoch - 17ms/step\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 18.8004 - mean_absolute_error: 18.8004 - val_loss: 13.5329 - val_mean_absolute_error: 13.5329 - 26s/epoch - 17ms/step\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 18.1760 - mean_absolute_error: 18.1760 - val_loss: 12.9873 - val_mean_absolute_error: 12.9873 - 26s/epoch - 17ms/step\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_m` which is not available. Available metrics are: loss,mean_absolute_error,val_loss,val_mean_absolute_error\n",
      "1532/1532 - 26s - loss: 17.6769 - mean_absolute_error: 17.6769 - val_loss: 12.8091 - val_mean_absolute_error: 12.8091 - 26s/epoch - 17ms/step\n",
      "01-22 16:39:49 I deeptables.m.deepmodel.py 122 - Training finished.\n",
      "01-22 16:39:49 I deeptables.m.deeptable.py 369 - Training finished.\n",
      "01-22 16:39:49 I deeptables.m.deeptable.py 704 - Model has been saved to:dt_output/dt_20240122163416_dnn_nets/dnn_nets.h5\n",
      "\n",
      " lgb model consumption training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: daypart: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:187\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:97\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, df_train_features)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py:1092\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1077\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    257\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:3433\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3427\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3428\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3429\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3430\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3431\u001b[0m     )\n\u001b[1;32m   3432\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3433\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3435\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:2462\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2456\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[1;32m   2457\u001b[0m                 data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   2458\u001b[0m                 used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2459\u001b[0m             )\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2463\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:2022\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[0;32m-> 2022\u001b[0m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:825\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    821\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    822\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 825\u001b[0m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    826\u001b[0m     feature_name,\n\u001b[1;32m    827\u001b[0m     categorical_feature,\n\u001b[1;32m    828\u001b[0m     pandas_categorical\n\u001b[1;32m    829\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:771\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[0;34m(data, target_dtype)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pandas_to_numpy\u001b[39m(\n\u001b[1;32m    768\u001b[0m     data: pd_DataFrame,\n\u001b[1;32m    769\u001b[0m     target_dtype: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.typing.DTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    770\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 771\u001b[0m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py:763\u001b[0m, in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[0;34m(pandas_dtypes_series)\u001b[0m\n\u001b[1;32m    757\u001b[0m bad_pandas_dtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype\u001b[38;5;241m.\u001b[39mtype)\n\u001b[1;32m    761\u001b[0m ]\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    764\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: daypart: object"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class CFG:\n",
    "    nn = True\n",
    "    lgb = True\n",
    "    ens_weights = {'nn': 0.5, 'lgb': 0.5}\n",
    "    epochs = 10\n",
    "    batch_size = 512\n",
    "    valid_size = 5e-2\n",
    "    LR_Scheduler = []  # [LR]\n",
    "    optimizer = AdamW(learning_rate=1e-3, weight_decay=9e-7)\n",
    "     \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.conf = ModelConfig(auto_imputation=True,\n",
    "                                auto_discrete=True,\n",
    "                                auto_discard_unique=True,\n",
    "                                categorical_columns='auto',\n",
    "                                fixed_embedding_dim=False,\n",
    "                                embeddings_output_dim=4,\n",
    "                                embedding_dropout=0.3,\n",
    "                                nets=['dnn_nets'],\n",
    "                                dnn_params={\n",
    "                                    'hidden_units': ((512, 0.3, True),\n",
    "                                                     (256, 0.3, True)),\n",
    "                                    'dnn_activation': 'relu',\n",
    "                                },\n",
    "                                stacking_op='add',\n",
    "                                output_use_bias=False,\n",
    "                                optimizer=CFG.optimizer,\n",
    "                                task='regression',\n",
    "                                loss='MeanAbsoluteError',\n",
    "                                metrics='MeanAbsoluteError',\n",
    "                                earlystopping_patience=1,\n",
    "                                )\n",
    "        \n",
    "        self.lgb_params = {\"n_estimators\": 2500,\n",
    "                           \"learning_rate\": 0.06,\n",
    "                           \"max_depth\": 16,\n",
    "                           \"num_leaves\": 500,\n",
    "                           \"reg_alpha\": 3.5,\n",
    "                           \"reg_lambda\": 1.5,\n",
    "                           \"colsample_bytree\": 0.9,\n",
    "                           \"colsample_bynode\": 0.6,\n",
    "                           \"min_child_samples\": 50,\n",
    "                           \"random_state\": 0,\n",
    "                           \"objective\": \"regression_l1\",\n",
    "                           \"device\": \"gpu\",\n",
    "                           \"n_jobs\": 4,\n",
    "                           \"verbose\": -1,\n",
    "                           }\n",
    "        \n",
    "        self.nn_model_consumption = DeepTable(config=self.conf)  \n",
    "        self.nn_model_production = DeepTable(config=self.conf)\n",
    "        \n",
    "        self.lgb_model_consumption = lgb.LGBMRegressor(**self.lgb_params)\n",
    "        self.lgb_model_production = lgb.LGBMRegressor(**self.lgb_params)\n",
    "\n",
    "    def fit(self, df_train_features):\n",
    "        print('nn = '+str(CFG.nn))\n",
    "        print('lgb = '+str(CFG.lgb))\n",
    "        \n",
    "        if CFG.nn == True:\n",
    "            \n",
    "            print('\\n',\"nn model consumption training.\",'\\n')\n",
    "            mask = df_train_features[\"is_consumption\"] == 1\n",
    "            self.nn_model_consumption.fit(\n",
    "                X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "                y=df_train_features[mask][\"target\"]\n",
    "                - df_train_features[mask][\"target_48h\"].fillna(0),\n",
    "                validation_split=CFG.valid_size, shuffle=False,\n",
    "                batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n",
    "                callbacks=CFG.LR_Scheduler\n",
    "            )\n",
    "        \n",
    "            # Avoid saving error\n",
    "            with K.name_scope(CFG.optimizer.__class__.__name__):\n",
    "                for i, var in enumerate(CFG.optimizer.weights):\n",
    "                    name = 'variable{}'.format(i)\n",
    "                    CFG.optimizer.weights[i] = tf.Variable(var, name=name)\n",
    "            self.conf = self.conf._replace(optimizer=CFG.optimizer)   \n",
    "            self.nn_model_production = DeepTable(config=self.conf)\n",
    "            \n",
    "            print('\\n',\"nn model production training.\",'\\n')\n",
    "            mask = df_train_features[\"is_consumption\"] == 0\n",
    "            self.nn_model_production.fit(\n",
    "                X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "                y=df_train_features[mask][\"target\"]\n",
    "                - df_train_features[mask][\"target_48h\"].fillna(0),\n",
    "                validation_split=CFG.valid_size, shuffle=False,\n",
    "                batch_size=CFG.batch_size, epochs=CFG.epochs, verbose=2,\n",
    "                callbacks=CFG.LR_Scheduler\n",
    "            )\n",
    "        \n",
    "        if CFG.lgb == True:\n",
    "            \n",
    "            print('\\n',\"lgb model consumption training.\")\n",
    "            mask = df_train_features[\"is_consumption\"] == 1\n",
    "            self.lgb_model_consumption.fit(\n",
    "                X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "                y=df_train_features[mask][\"target\"]\n",
    "                - df_train_features[mask][\"target_48h\"].fillna(0),\n",
    "            )\n",
    "        \n",
    "            print('\\n',\"lgb model production training.\",'\\n')\n",
    "            mask = df_train_features[\"is_consumption\"] == 0\n",
    "            self.lgb_model_production.fit(\n",
    "                X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "                y=df_train_features[mask][\"target\"]\n",
    "                - df_train_features[mask][\"target_48h\"].fillna(0),\n",
    "            )\n",
    "        \n",
    "    def plot_nn_model(self):\n",
    "        if CFG.nn == True:\n",
    "            return plot_model(self.nn_model_consumption.get_model().model)    \n",
    "\n",
    "    def predict(self, df_features):\n",
    "        predictions = np.zeros(len(df_features))\n",
    "        \n",
    "        if CFG.nn == True and CFG.lgb == True:\n",
    "            \n",
    "            print('\\n',\"nn & lgb model consumption prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 1\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + CFG.ens_weights['nn'] * (self.nn_model_consumption.predict(df_features[mask])[:,0])\n",
    "                + CFG.ens_weights['lgb'] * (self.lgb_model_consumption.predict(df_features[mask])),\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "        \n",
    "            print('\\n',\"nn & lgb model production prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 0\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + CFG.ens_weights['nn'] * (self.nn_model_production.predict(df_features[mask])[:,0])\n",
    "                + CFG.ens_weights['lgb'] * (self.lgb_model_production.predict(df_features[mask])),\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "        \n",
    "        elif CFG.nn == True and CFG.lgb == False:\n",
    "            \n",
    "            print('\\n',\"nn model consumption prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 1\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + self.nn_model_consumption.predict(df_features[mask])[:,0],\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "            \n",
    "            print('\\n',\"nn model production prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 0\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + self.nn_model_production.predict(df_features[mask])[:,0],\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "            \n",
    "        elif CFG.nn == False and CFG.lgb == True:\n",
    "            \n",
    "            print('\\n',\"lgb model consumption prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 1\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + self.lgb_model_consumption.predict(df_features[mask]),\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "            \n",
    "            print('\\n',\"lgb model production prediction.\",'\\n')\n",
    "            mask = df_features[\"is_consumption\"] == 0\n",
    "            predictions[mask.values] = np.clip(\n",
    "                df_features[mask][\"target_48h\"].fillna(0).values\n",
    "                + self.lgb_model_production.predict(df_features[mask]),\n",
    "                0,\n",
    "                np.inf,\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"No models has been trained.\")\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "model.fit(df_train_features)\n",
    "\n",
    "joblib.dump(model.lgb_model_consumption, 'lgb_model_consumption.joblib')\n",
    "joblib.dump(model.lgb_model_production, 'lgb_model_production.joblib')\n",
    "# lgb_model_consumption = joblib.load('lgb_model_consumption.joblib')\n",
    "# lgb_model_production = joblib.load('lgb_model_production.joblib')\n",
    "\n",
    "nn_model_consumption = model.nn_model_consumption.get_model().model\n",
    "nn_model_consumption.save('nn_model_consumption.h5')\n",
    "\n",
    "nn_model_production = model.nn_model_production.get_model().model\n",
    "nn_model_production.save('nn_model_production.h5')\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model_file = 'nn_model_production.h5'\n",
    "# loaded_model = load_model(model_file)\n",
    "\n",
    "clean_memory()\n",
    "model.plot_nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
